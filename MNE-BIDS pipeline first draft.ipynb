{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62056a25",
   "metadata": {},
   "source": [
    "# MNE-BIDS pipeline\n",
    ">\n",
    "#### This document will serve as a step-by-step guide to walk you through transforming your EEG dataset into one compliant with the BIDS format, using MNE-BIDS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28eba06a",
   "metadata": {},
   "source": [
    "### What is MNE?\n",
    "> MNE is an open source python package for working with EEG and MEG data, which serves to facilitate the exploration, visualisation and analysis of neuroimaging data."
   ]
  },
  {
   "attachments": {
    "BIDS hierarchy.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "5eca1136",
   "metadata": {},
   "source": [
    "### What is BIDS?\n",
    "> BIDS (Brain Imaging Data Structure) is a simple method of organising neuroimaging data that is easy to adopt and promotes standardisation across neuroimaging experiments. This allows for easier, more open data sharing and collaboration.\n",
    ">\n",
    "> It involves a hierarchical folder organisation structure, with four main levels:\n",
    ">\n",
    "> ![BIDS hierarchy.png](<attachment:BIDS hierarchy.png>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45baf688",
   "metadata": {},
   "source": [
    "## SO, MNE-BIDS...?\n",
    "> Is a processing pipeline that uses MNE-python tools to generate BIDS compliant datasets!\n",
    ">\n",
    "If you don't currently have MNE-BIDS installed, please refer to their official [website](https://mne.tools/mne-bids-pipeline/stable/getting_started/install.html) to do so before beginning this walkthrough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5588cc48",
   "metadata": {},
   "source": [
    "# What versions will this document use?\n",
    "\n",
    "#### - MNE version: 1.9.0\n",
    "#### - BIDS version: 1.10.0\n",
    "#### - MNE-BIDS version: 0.16.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc508c83",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2866c154",
   "metadata": {},
   "source": [
    "# Expected Proficiencies\n",
    "> #### Prior to using this pipeline, a certain level of understanding/ skill is expected. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e572f6dd",
   "metadata": {},
   "source": [
    "This entails:\n",
    "- Some knowledge of python (to understand and implement the present code), although this will be explained throughout.\n",
    "- An understanding of what a BIDS formatted dataset should include and how it should look (for checking the dataset has converted correctly).\n",
    "  > This information can be found on the [BIDS website](https://bids.neuroimaging.io/getting_started/index.html).\n",
    "- Familiarity with your EEG dataset and its associated metadata (to ensure all important information is present post-conversion and add any that is missing)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b96f5df",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481f30e7",
   "metadata": {},
   "source": [
    "# 1. Downloading data\n",
    "> #### Collecting the EEG dataset necessary to run through this pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb325c6",
   "metadata": {},
   "source": [
    "In order to complete this pipeline, you will first need some EEG data. If you intend to run this pipeline using your pre-existing dataset, you can simply move onto the next step. If you don't have any EEG data to test this process on, we suggest downloading the [EEG Motor Movement/Imagery Dataset](https://physionet.org/content/eegmmidb/1.0.0/) from the [Physiobank Database](https://physionet.org/data/). \n",
    "\n",
    "[Link this to all of the rest of the document (edit the files to fit it in)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd2b600",
   "metadata": {},
   "source": [
    "GIVE LINK TO DOWNLOAD FULL CODE FROM DOC just like MNE does [At bottom]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c438d4",
   "metadata": {},
   "source": [
    "# 2. Data formatting\n",
    "> #### This pipeline's data format expectations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28464a6e",
   "metadata": {},
   "source": [
    "This pipeline is curated to work with EEGLab (brainvision and _EDF_ are recommended by MNE) formatted datasets, however MNE is capable of handling a variety of formats. \n",
    ">  If your data is currently in a different format, you will need to use a slightly different section of code when reading in your data (step 6). For guidance on this, refer to MNE's documentation on [importing data from EEG devices](https://mne.tools/stable/auto_tutorials/io/20_reading_eeg_data.html#sphx-glr-auto-tutorials-io-20-reading-eeg-data-py) for guidance. \n",
    ">\n",
    "The pipeline will also write the dataset into a BIDS-recommended format [EEGLab or BrainVision or EDF] in step 7. If you require a different output format, you may edit the `format` parameter of `write_raw_bids` using [MNE's guidance](https://mne.tools/mne-bids/stable/generated/mne_bids.write_raw_bids.html).\n",
    "\n",
    "USE THE DATA FORMAT OF THE PHYSIOBANK ONE ONCE SWITCHED OVER (EDF????)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3bc51d",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a62ce0",
   "metadata": {},
   "source": [
    "# 3. Importing the necessary tools\n",
    ">### To begin, we will need to import all the tools necessary for converting the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc978cc5",
   "metadata": {},
   "source": [
    "This first section of code will import tools that allow us to work with the file paths and simplify the method of handling them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa3095e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Allows us to work with file paths\n",
    "import os.path as op\n",
    "#Makes file path handling simpler\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222527de",
   "metadata": {},
   "source": [
    "Next, we need to `import MNE`, a python package for working with EEG and MEG data, and some associated tools that we will use here. \n",
    ">\n",
    "From `mne_bids`, we are importing:\n",
    "- `BIDSPath`:\n",
    "A tool for creating a BIDS formatted file path\n",
    "- `print_dir_tree`:\n",
    "A tool for presenting the contents of a folder in a 'tree' view\n",
    "- `write_raw_bids`:\n",
    "A tool for saving EEG data into BIDS format\n",
    ">\n",
    "Additionally, we wil be installing MNE-BIDS using [pip](https://pypi.org/project/pip/) (a package installer), before ensuring that MNE-BIDS is upgraded to be the newest version, to allow smooth functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8117ec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "%pip install mne_bids\n",
    "%pip install --upgrade mne_bids\n",
    "\n",
    "from mne_bids import BIDSPath, print_dir_tree, write_raw_bids, make_dataset_description, update_sidecar_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c40bee",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd272f5d",
   "metadata": {},
   "source": [
    "# 4. Finding the data\n",
    ">### After completing our imports, we need to find the EEG data files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fbeb4d",
   "metadata": {},
   "source": [
    "In the code below, the first line specifies where the folders and sub-folders for the data can be found. These should include your EEG data and any additional information (metadata). \n",
    ">\n",
    "You should modify this to include your own file pathway: `data_dir = Path(r\"___your file pathway____\")`. This should be the file containing your task files, or the highest file level containing your dataset and no external (dataset-unrelated) files.\n",
    "> Here, the `r` (raw) ensures the file location is read as is, and that the backslashes don't get interpreted as special characters, so don't break up the text.\n",
    ">\n",
    "The line below this prints a visualisation of the first sub-folders within (using the `print_dir_tree` tool!). \n",
    "> You may have 1 or more of these, depending on how much EEG data you wish to make BIDS compliant. Each of these should contain EEG data from one specific task type, including data from each participant and any associated metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069ad766",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the file path to your data's location\n",
    "data_dir = Path(r\"C:\\N8_internship_code\\source_data\")\n",
    "print_dir_tree(data_dir, max_depth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0500035",
   "metadata": {},
   "source": [
    "This next section lists the file paths for the sub-folders we just visualised and adds them to the list 'children'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab5a02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "children = [child for child in data_dir.iterdir()]\n",
    "children"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cef6ebe",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35b5456",
   "metadata": {},
   "source": [
    "# 5. Selecting specific files\n",
    ">### Let's specify the files we want to use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fd7eb1",
   "metadata": {},
   "source": [
    "Here, the first line serves to identify which of the two files we want to write into BIDS format (note: in python, the first index is given a value of 0). If you have multiple files, each time you run through this you should change the number at the end to match the file you are wanting to adapt. \n",
    ">\n",
    "The second line lists all the files in the specified subfolder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8554874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change this to match the file number\n",
    "dir_number = 0\n",
    "files = [file for file in children[dir_number].iterdir()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1342cd1",
   "metadata": {},
   "source": [
    "This sets the first file in the folder to the variable `file_path`, then prints this. \n",
    ">\n",
    "Even when completing multiple iterations (for more than one dataset), the value should NOT be changed from 0!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da3668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = files[0]\n",
    "file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bffe158",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932801a0",
   "metadata": {},
   "source": [
    "# 6. Reading the data\n",
    ">### Now we've completed our preparations, lets compile our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae205c9",
   "metadata": {},
   "source": [
    "Here, we are reading the EEG data from the previously selected file path to the `data` variable.\n",
    ">\n",
    "As previously mentioned, the current code is tailored to EEGLab formatted datasets and won't work with any other formats. As such, you must use a slightly different line of code depending on the format of your data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b896a11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mne.io.read_raw_eeglab(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d40778",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1d74bc",
   "metadata": {},
   "source": [
    "Here, we will specify the line frequency for the dataset, as required by BIDS. You should change the number here to reflect the line frequency of your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03292ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify line frequency\n",
    "data.info[\"line_freq\"] = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d0a64a",
   "metadata": {},
   "source": [
    "How to add montage here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef60ea5e",
   "metadata": {},
   "source": [
    "Printing `data` will display the data's information. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd970fd",
   "metadata": {},
   "source": [
    "This next section of code will create a new folder path for storing EEG data in BIDS format, then prints it out. \n",
    ">\n",
    "We recommend renaming your file to something more specific to your dataset, by switching out the text in the quotation marks (`\"bids_example\"`). Attempt to avoiding using any spaces in the title to prevent possible later complications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed8d54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bids_root = op.join(data_dir.parent, \"bids_example\")\n",
    "bids_root"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53eaa835",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c23650",
   "metadata": {},
   "source": [
    "# 7. Writing the data\n",
    "> #### Let's write our selected data into BIDS format!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54eae464",
   "metadata": {},
   "source": [
    "First, you should manually define the partricipant number/ subject id and task name for this dataset, setting them each to a variable as seen in the first two rows.\n",
    ">\n",
    "Then, using the `BIDSPath` tool we imported earlier, we will assign the subject, task and the folder path we just created to `bids_path`. \n",
    ">\n",
    "We will then use another imported tool, `write_raw_bids` to write the data (from the file path we defined earlier) into the new file path we created, linking it to the subject id and task type we outlined. The desired format of the output data is also outlined here `format=\"EEGLAB\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569683cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Edit this information ot match your data\n",
    "subject_id = \"001\"\n",
    "task = \"rest\"\n",
    "\n",
    "bids_path = BIDSPath(subject=subject_id, task=task, root=bids_root)\n",
    "write_raw_bids(data, bids_path, overwrite=True, allow_preload=True, format=\"EEGLAB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe4597c",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c9b874",
   "metadata": {},
   "source": [
    "### Now you have formatted your dataset to BIDS standards! \n",
    "#### Don't forget to repeat steps 4 and 5 for all of the file paths we found in step 3\n",
    ">\n",
    "## But hold on!\n",
    "#### Your BIDS formatted dataset isn't quite complete yet..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a65353b",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f10e503",
   "metadata": {},
   "source": [
    "# Editing and checking your BIDS formatted dataset\n",
    "### The steps below will walk you through finding and editing some of the files in your new dataset, in order to make them BIDS-compliant. \n",
    "Each of these files should automatically include a large amount of information derived from your dataset and stored in BIDS format, however this may not always be completely accurate.\n",
    ">\n",
    "As such, the next steps will walk you through checking that your BIDS dataset is accurate, and how to adapt these files if necessary. Some of the file's items will be deemed required for a BIDS-compliant dataset, while others are recommended or merely optional. You __MUST__ ensure that the required elements are present and have correct data, and although not necessary, it will be beneficial for you to include as much additional data as possible, especially if it is important information for your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1999b7d4",
   "metadata": {},
   "source": [
    "You can do this by navigating to the file path we assigned to the variable `bids_root` in step 4, then working through all of the files and investigating what is present/correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3ecd93",
   "metadata": {},
   "source": [
    "# Editing different file formats\n",
    "Some of the following files will follow the .json format (Sidecar, Coordinate System, Dataset Description), others (Channels Description, Electrodes description) will be in the .tsv format, and a few will have a file in each format (Events, Participants).\n",
    "\n",
    "These file types are each edited via slightly different methods, so while .json files require no extra imports, to edit our .tsv files we must import the [pandas](https://pandas.pydata.org/pandas-docs/version/1.4/index.html) library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e82cb5",
   "metadata": {},
   "source": [
    "Due to the differences in their display formats (text vs tabular), while .json files can be edited using a simple dictionary of key:value pairs, editing .tsv files requires a few different code functions. \n",
    "\n",
    "Those outlined in this document will walk you through:\n",
    "- Adding/ Editing a column\n",
    "- Editing the value of just one row\n",
    "- Removing a row\n",
    "- Adding a row\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c5dcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the pandas library to edit .tsv files\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0828cf",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14e2378",
   "metadata": {},
   "source": [
    "# File 1. Sidecar.json\n",
    ">\n",
    "This file's name should have a naming format simlilar to *_eeg.json in your 'eeg' subfolder. \n",
    "\n",
    "Once you have located the file, you should open it and look through its parameters. Below is a list of information BIDS needs/suggests for this file. \n",
    "> Take note of any elements that are missing/incorrect; these can be updated using the next section of code.\n",
    ">\n",
    "#### BIDS components:\n",
    ">\n",
    "Necessary:\n",
    ">\n",
    "    1. EEGReference\n",
    "    2. SamplingFrequency\n",
    "    3. PowerlineFrequency\n",
    "    4. SoftwareFilters\n",
    "    5. TaskName\n",
    ">\n",
    "Recommended:\n",
    ">\n",
    "    6. TaskDescription\n",
    "    7. Instructions\n",
    "    8. CogAtlasID\n",
    "    9. CogPOID\n",
    "    10. CapManufacturer\n",
    "    11. CapManufacturer'sModelName\n",
    "    12. SoftwareVersions\n",
    "    13. DeviceSerialNumber\n",
    "    14. EEGChannelCount\n",
    "    15. ECGChannelCount\n",
    "    16. EMGChannelCount\n",
    "    17. EOGChannelCount\n",
    "    18. MISCChannelCount\n",
    "    19. TriggerChannelCount\n",
    "    20. RecordingDuration\n",
    "    21. RecordingType\n",
    "    22. EpochLength\n",
    "    23. EEGGround\n",
    "    24. HeadCircumference\n",
    "    25. EEGPlacementScheme\n",
    "    26. HardwareFilters\n",
    "    27. SubjectArtefactDescription\n",
    "    28. InstitutionName\n",
    "    29. InstitutionAddress\n",
    "    30. InstitutionalDepartment Name\n",
    ">\n",
    "Optional:\n",
    ">\n",
    "    31. ElectricalStimulation\n",
    "    32. ElectricalStimulationParameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c269e8be",
   "metadata": {},
   "source": [
    "## Manually updating an element in the JSON file. \n",
    ">\n",
    "To begin, you must edit the first line of code to match your file path `Path(r'___Your file path here___')`, and the second line to match your files directory `root = (r'__Your file directory here__')`. Additionally, you must change the `subject=` and `task=` sections of `bids_path1` to match your dataset's file name.\n",
    "\n",
    "Once these are re-defined, you can update one or more aspect(s) of the sidecar using the `entries = {}` dictionary. This accepts `key:value` pairs, separated by colons (:), wherein single quotation marks ('') indicate a parameter name, while double quotation marks (\"\") indicate it's data entry.\n",
    ">\n",
    "##### The code below will display an example of a few formats the key-value pairs can present in, such as:\n",
    "__Numerical__\n",
    "    - A key-value pair where the value is a number (int/float).\n",
    ">\n",
    "__Written__\n",
    "    - A key-value pair where the value is a string (text).\n",
    ">\n",
    "__Nested dictionary (1 level)__\n",
    "    - A key-value pair where the value is a dictionary containing key-value pairs.\n",
    ">\n",
    "__Nested dictionary (2+ levels)__\n",
    "    - A key-value pair where the value is a dictionary that contains one or more dictionaries.\n",
    ">\n",
    "\n",
    " > An example output file can be found within the [BIDS documentation](https://bids-specification.readthedocs.io/en/stable/modality-specific-files/electroencephalography.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc49e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#updating a specific parameter in the sidecar JSON file\n",
    "json_file = Path(r'C:\\N8_internship_code\\bids_example\\sub-001\\eeg\\sub-001_task-rest_eeg.json').absolute()\n",
    "# Create BIDSPath using the JSON file's directory as root\n",
    "root = (r'C:\\N8_internship_code\\bids_example')\n",
    "\n",
    "bids_path1 = BIDSPath(subject='001', task='rest',\n",
    "                     suffix='eeg', extension='.json', datatype='eeg',\n",
    "                     root=root)\n",
    "\n",
    "entries = {# Simple key-value pair for power line frequency (numerical)\n",
    "           'PowerLineFrequency': 50.0,\n",
    "           # Simple key-value pair for task name (written)\n",
    "            'TaskName': \"Resting State\",\n",
    "            # Nested dictionary for software versions (1-level)\n",
    "            'SoftwareVersions' : {\n",
    "                'MNE': \"1.9.0\",\n",
    "                'BIDS': \"1.10.0\",\n",
    "                'MNE-BIDS': \"0.16.0\"\n",
    "                },\n",
    "           # Nested dictionary for software filters (2-levels)\n",
    "           'SoftwareFilters': {\n",
    "                \"Anti-aliasing filter\":{\n",
    "                \"half-amplitude cutoff (Hz)\": 500,\n",
    "                \"Roll-off\": \"6dB/Octave\"\n",
    "                }\n",
    "                },\n",
    "            }   \n",
    "\n",
    "# Update the JSON file with your new entries\n",
    "update_sidecar_json(bids_path1, entries, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca242e97",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9172f231",
   "metadata": {},
   "source": [
    "# File 2. Channels Description\n",
    ">\n",
    "This should have a format simlilar to *_channels.tsv in your 'eeg' subfolder. \n",
    "\n",
    "Once you have located the file, you should open it and look through the components it lists. Below is a list of information BIDS needs/suggests for this file. Take note of which elemets are missing or incorrect.\n",
    ">\n",
    "#### BIDS components:\n",
    ">\n",
    "Necessary:\n",
    ">\n",
    "    1. Name\n",
    "    2. Type\n",
    "    3. Units\n",
    "Recommended\n",
    ">\n",
    "    n/a\n",
    ">\n",
    "Optional:\n",
    ">\n",
    "    4. Description\n",
    "    5. SamplingFrequency\n",
    "    6. Reference\n",
    "    7. LowCutoff\n",
    "    8. HighCutoff\n",
    "    9. Notch\n",
    "    10. Status\n",
    "    11. StatusDescription"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a55044",
   "metadata": {},
   "source": [
    "## Manually updating the channels.tsv file:\n",
    "To edit this file, we must first edit the file path in the single quotation marks ('') to match the location of your `channels.tsv` file. \n",
    "\n",
    "This will ensure that the variable `channels_tsv` refers to the file we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d09e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the channels.tsv file to a variable\n",
    "channels_tsv = pd.read_csv(r'C:\\N8_internship_code\\bids_example\\sub-001\\eeg\\sub-001_task-rest_channels.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be963ea",
   "metadata": {},
   "source": [
    "#### Adding/ Editing a column:\n",
    "\n",
    "Both of these functions can be managed using the same section of code!\n",
    "\n",
    "First, you should edit the 'Inputs' list to include the variables you wish to add to your new or pre-existing column. This should be done in participant order, beginning with the entry for the first participant in the file, and an entry must be submitted for each row.\n",
    "\n",
    "Then, you should change the text in double quotation marks (\"\") within `channels_tsv[\"__\"]`, to either title of the pre-existing column you wish to add to, or the title of the new column you wish to generate.\n",
    "\n",
    "Next, you should edit the file paths in the single quotation marks ('') to the location of your `channels.tsv` file, as we did above. This ensures that the code knows what file it's writing to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53609125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing the desired inputs for the \"status\" column\n",
    "Inputs = [\"Good\", \"Bad\", \"Average\"]  \n",
    "\n",
    "# Setting the rows in the \"status\" column to the inputs listed above\n",
    "channels_tsv[\"status\"] = Inputs\n",
    "\n",
    "#writing the change to the file\n",
    "channels_tsv.to_csv(r'C:\\N8_internship_code\\bids_example\\sub-001\\eeg\\sub-001_task-rest_channels.tsv', sep= '\\t', index=False, na_rep='n/a')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd75cfe2",
   "metadata": {},
   "source": [
    "#### Editing one row:\n",
    " \n",
    "To edit a single row, you must use the `.loc` function, which allows us to select a row via it's label. In this case, we will use 'name', by editing the name of the channel (in the second set of double quotation marks) to match that of the row you'd like to edit. \n",
    "\n",
    "From there, you can edit the column name to match the one you'd like to edit (in the third set of double quotation marks) and then the item you;d like to assign to the location (in the fourth set of double quotation marks).\n",
    "\n",
    "Then, after changing file location in the last line to match your own, we can write the changes to the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2412504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Editing just one row in the channels.tsv file\n",
    "channels_tsv.loc[channels_tsv[\"name\"] == \"Fp1\", \"status\"] = \"good\"\n",
    "\n",
    "# Writing the change to the file\n",
    "channels_tsv.to_csv(r'C:\\N8_internship_code\\bids_example\\sub-001\\eeg\\sub-001_task-rest_channels.tsv', sep= '\\t', index=False, na_rep='n/a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a92daf8",
   "metadata": {},
   "source": [
    "#### Removing a row:\n",
    "\n",
    "To remove a row, you must use the `.drop` function, to which you assign an index, which is the number assigned to the row you wish to remove. \n",
    "Note: Indexes begin from 0, so the 'first' row will be #0, the 'second' row will be #1 and so on.\n",
    "\n",
    "Then, after the file location in the last line has been changed to match your own, we can write the changes to the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b866f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing a row from the channels.tsv file using the row's index\n",
    "channels_tsv = channels_tsv.drop(index=1)\n",
    "\n",
    "# Writing the change to the file\n",
    "channels_tsv.to_csv(r'C:\\N8_internship_code\\bids_example\\sub-001\\eeg\\sub-001_task-rest_channels.tsv', sep= '\\t', index=False, na_rep='n/a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32362096",
   "metadata": {},
   "source": [
    "#### Adding a row:\n",
    "\n",
    "To add a row, you must first create a new data frame containing all of the columns and their values (in key:value pairs) that you want to add to the new row (do so by editing the text in the double quotation marks in the first line, and adding new key:value pairs where necessary). \n",
    "\n",
    "This will then be combined with the current data frame (channels_tsv), and once you have changed the file location in the last line to match your own, these edits can be written to the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add70770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new data frame for the new row\n",
    "new_channels_row = pd.DataFrame([{\"name\": \"F3\", \"type\": EEG, \"units\":\"V\"}])\n",
    "\n",
    "# Combining the new row with the existing channels_tsv data frame\n",
    "channels_tsv = pd.concat([channels_tsv, new_channels_row], ignore_index=True)\n",
    "\n",
    "# Writing the change to the file\n",
    "channels_tsv.to_csv(r'C:\\N8_internship_code\\bids_example\\sub-001\\eeg\\sub-001_task-rest_channels.tsv', sep= '\\t', index=False, na_rep='n/a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf93bd3f",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d72916",
   "metadata": {},
   "source": [
    "# File 3. Electrodes Description \n",
    "This should have a format simlilar to *_electrodes.tsv in your 'eeg' subfolder. \n",
    "\n",
    "Once you have located the file, you should open it and look through the components it lists. Below is a list of information BIDS needs/suggests for this file. Take note of which elemets are missing/incorrect.\n",
    ">\n",
    "#### BIDS components:\n",
    ">\n",
    "Necessary:\n",
    ">\n",
    "    1. X\n",
    "    2. Y\n",
    "    3. Z\n",
    ">\n",
    "Recommended:\n",
    ">\n",
    "    4. Type\n",
    "    5. Material\n",
    "    6. Impedance\n",
    ">\n",
    "Optional:\n",
    ">\n",
    "    n/a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e455eadf",
   "metadata": {},
   "source": [
    "## Manually updating the electrodes.tsv file:\n",
    "To edit this file, we must first edit the file path in the single quotation marks ('') to match the location of your `electrodes.tsv` file. \n",
    "\n",
    "This will ensure that the variable `electrodes_tsv` refers to the file we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5d0849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the electrodes.tsv file to a variable\n",
    "electrodes_tsv = pd.read_csv(r'C:\\N8_internship_code\\bids_example\\sub-001\\eeg\\sub-001_space-CapTrak_electrodes.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25a8c5f",
   "metadata": {},
   "source": [
    "#### Adding/ Editing a column:\n",
    "\n",
    "Both of these functions can be managed using the same section of code!\n",
    "\n",
    "First, you should edit the 'Inputs' list to include the variables you wish to add to your new or pre-existing column. This should be done in participant order, beginning with the entry for the first participant in the file, and an entry must be submitted for each row.\n",
    "\n",
    "Then, you should change the text in double quotation marks (\"\") within `electrodes_tsv[\"__\"]`, to either title of the pre-existing column you wish to add to, or the title of the new column you wish to generate.\n",
    "\n",
    "Next, you should edit the file paths in the single quotation marks ('') to the location of your `electrodes.tsv` file, as we did above. This ensures that the code knows what file it's writing to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecdfa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing the desired inputs for the \"z\" column\n",
    "Inputs = [\"0.0\", \"0.049\", \"-0.039\", \"0.07\"]  \n",
    "\n",
    "# Setting the rows in the \"z\" column to the inputs listed above\n",
    "participants_tsv[\"z\"] = Inputs\n",
    "\n",
    "# Writing the change to the file\n",
    "participants_tsv.to_csv(r'C:\\N8_internship_code\\bids_example\\sub-001\\eeg\\sub-001_space-CapTrak_electrodes.tsv', sep= '\\t', index=False, na_rep='n/a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7777b1b7",
   "metadata": {},
   "source": [
    "#### Editing one row:\n",
    " \n",
    "To edit a single row, you must use the `.loc` function, which allows us to select a row via it's label. In this case, we will use participant ID, by editing the participant ID number (in the second set of double quotation marks) to match that of the row you'd like to edit. \n",
    "\n",
    "From there, you can edit the column name to match the one you'd like to edit (in the third set of double quotation marks) and then the item you;d like to assign to the location (in the fourth set of double quotation marks).\n",
    "\n",
    "Then, after changing file location in the last line to match your own, we can write the changes to the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f641e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Editing just one row in the participants.tsv file\n",
    "participants_tsv.loc[participants_tsv[\"participant_id\"] == \"sub-001\", \"Education\"] = \"none\"\n",
    "\n",
    "# Writing the change to the file\n",
    "participants_tsv.to_csv(r'C:\\N8_internship_code\\bids_example\\sub-001\\eeg\\sub-001_space-CapTrak_electrodes.tsv', sep= '\\t', index=False, na_rep='n/a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9aa3bd",
   "metadata": {},
   "source": [
    "#### Removing a row:\n",
    "\n",
    "To remove a row, you must use the `.drop` function, to which you assign an index, which is the number assigned to the row you wish to remove. \n",
    "Note: Indexes begin from 0, so the 'first' row will be #0, the 'second' row will be #1 and so on.\n",
    "\n",
    "Then, after the file location in the last line has been changed to match your own, we can write the changes to the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b6abfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing a row from the participants.tsv file using the row's index\n",
    "participants_tsv = participants_tsv.drop(index=1)\n",
    "\n",
    "# Writing the change to the file\n",
    "participants_tsv.to_csv(r'C:\\N8_internship_code\\bids_example\\sub-001\\eeg\\sub-001_space-CapTrak_electrodes.tsv', sep= '\\t', index=False, na_rep='n/a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f500f64e",
   "metadata": {},
   "source": [
    "#### Adding a row:\n",
    "\n",
    "To add a row, you must first create a new data frame containing all of the columns and their values (in key:value pairs) that you want to add to the new row (do so by editing the text in the double quotation marks in the first line, and adding new key:value pairs where necessary). \n",
    "\n",
    "This will then be combined with the current data frame (participants_tsv), and once you have changed the file location in the last line to match your own, these edits can be written to the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c90e569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new data frame for the new row\n",
    "new_participants_row = pd.DataFrame([{\"participant_id\": \"sub-002\", \"age\": 30, \"sex\":\"M\"}])\n",
    "\n",
    "# Combining the new row with the existing participants_tsv data frame\n",
    "participants_tsv = pd.concat([participants_tsv, new_participants_row], ignore_index=True)\n",
    "\n",
    "# Writing the change to the file\n",
    "participants_tsv.to_csv(r'C:\\N8_internship_code\\bids_example\\sub-001\\eeg\\sub-001_space-CapTrak_electrodes.tsv', sep= '\\t', index=False, na_rep='n/a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0695bc77",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b34933",
   "metadata": {},
   "source": [
    "# File 4. Coordinate System\n",
    "This should have a naming format simlilar to *_coordsystem.json in your 'eeg' subfolder. \n",
    "\n",
    "Once you have located the file, you should open it and look through its parameters. Below is a list of information BIDS needs/suggests for this file. \n",
    ">Take note of any elements that are missing/incorrect; these can be updated using the next section of code.\n",
    "\n",
    "#### BIDS components:\n",
    ">\n",
    "Necessary:\n",
    ">\n",
    "    1. EEGCoordinateSystem\n",
    "    2. EEGCoordinateUnits\n",
    "    3. EEGCoordinateSystemDescription\n",
    "Recommended:\n",
    ">\n",
    "    4. FiducialsDescription\n",
    "    5. FiducialsCoordinates\n",
    "    6. FiducialsCoordinateSystem\n",
    "    7. FiducialsCoordinateUnits\n",
    "    8. FiducialsCoordinateSystemDescription\n",
    "    9. AnatomicalLandmarkCoordinates\n",
    "    10. AnatomicalLandmarkCoordinateSystem\n",
    "    11. AnatomicalLandmarkCoordinateUnits\n",
    "    12. AnatomicalLandmarkCoordinateSystemDescription\n",
    ">\n",
    "Optional:\n",
    ">\n",
    "    13. IntendedFor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4386fe0b",
   "metadata": {},
   "source": [
    "## Manually updating an element in the JSON file\n",
    "As with the sidecar file, the first line of code should be edited to match your file path `Path(r'___Your file path here___')`, and the second line to match your files directory `root = (r'__Your file directory here__')`. Additionally, you must change the `subject=` and `space=` sections of `bids_path1` to match your dataset's file name.\n",
    "\n",
    "For this file, the `space=` section is defined as CapTrak; if you were using a different coordinate system, its name should be inputted here instead.\n",
    "\n",
    "Once these are re-defined, you can update one or more aspect(s) of the sidecar using the `entries = {}` dictionary. This accepts `key:value` pairs, separated by colons (:), wherein single quotation marks ('') indicate a parameter name, while double quotation marks (\"\") indicate it's data entry.\n",
    ">\n",
    "##### The code below will display an example of a few formats the key-value pairs can present in, such as:\n",
    ">\n",
    "__Written__\n",
    "    - A key-value pair where the value is a string (text).\n",
    ">\n",
    "__Nested dictionary (1 level)__\n",
    "    - A key-value pair where the value is a dictionary containing key-value pairs.\n",
    ">\n",
    "- Note: This file will accept key-value pairs in other formats, but those represented here are the only formats _necessary_.\n",
    "\n",
    "> An example output file can be found within the [BIDS documentation](https://bids-specification.readthedocs.io/en/stable/modality-specific-files/electroencephalography.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05d3a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating a specific parameter in the coordinate system JSON file\n",
    "json_file = Path(r'C:\\N8_internship_code\\bids_example\\sub-001\\eeg\\sub-001_space-CapTrak_coordsystem.json').absolute()\n",
    "# Create BIDSPath using the JSON file's directory as root\n",
    "root = Path(r'C:\\N8_internship_code\\bids_example')\n",
    "\n",
    "\n",
    "bids_path1 = BIDSPath(subject='001', task=None,\n",
    "                     suffix='coordsystem', extension='.json', datatype='eeg',\n",
    "                     root=root, space='CapTrak')\n",
    "\n",
    "entries = { # Simple key-value pair for EEG Coordinate System (written)\n",
    "            'EEGCoordinateSystem':\"CapTrak\",\n",
    "            # Nested dictionary for Anatomical Landmark Coordinates, with list values (1-level)\n",
    "            'AnatomicalLandmarkCoordinates': {\n",
    "                'Nasion': [0.0, 0.0, 0.0],\n",
    "                'Left Preauricular': [-0.1, 0.0, 0.0],\n",
    "                'Right Preauricular': [0.1, 0.0, 0.0]\n",
    "            },\n",
    "            }       \n",
    "# Update the JSON file with your new entries\n",
    "update_sidecar_json(bids_path1, entries, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6428e4ea",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280c7d49",
   "metadata": {},
   "source": [
    "# File 5. Events.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f91b9da",
   "metadata": {},
   "source": [
    "# File 6. Events.json\n",
    "This file's name should have a format simlilar to *_events.json in your 'eeg' subfolder. \n",
    "\n",
    "Once you have located the file, you should open it and look through its parameters. Below is a list of information BIDS needs/suggests for this file. \n",
    "> Take note of any elements that are missing/incorrect; these can be updated using the next section of code.\n",
    ">\n",
    "#### BIDS components:\n",
    ">\n",
    "Necessary:\n",
    ">\n",
    "    1. Onset\n",
    "    2. Duration\n",
    ">\n",
    "Recommended:\n",
    ">\n",
    "    n/a\n",
    ">\n",
    "Optional:\n",
    ">\n",
    "    3. TrialType\n",
    "    4. ResponseTime\n",
    "    5. HED\n",
    "    6. StimFile\n",
    "    7. Channel\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cf72e7",
   "metadata": {},
   "source": [
    "## Manually editing an element in the JSON file\n",
    "Similarly to the procedure for the other JSON files, the first line of code should be edited to match your file path `Path(r'___Your file path here___')`, and the second line to match your files directory `root = (r'__Your file directory here__')`. Additionally, you must change the `subject=` and `task=` sections of `bids_path1` to match your dataset's file name.\n",
    "\n",
    "Once these are re-defined, you can update one or more aspect(s) of the sidecar using the `entries = {}` dictionary. This accepts `key:value` pairs, separated by colons (:), wherein single quotation marks ('') indicate a parameter name, while double quotation marks (\"\") indicate it's data entry.\n",
    ">\n",
    "##### The code below will display an example of a few formats the key-value pairs can present in, such as:\n",
    "__Nested dictionary (1 level)__\n",
    "    - A key-value pair where the value is a dictionary containing key-value pairs.\n",
    ">\n",
    "__Nested dictionary (2+ levels)__\n",
    "    - A key-value pair where the value is a dictionary that contains one or more dictionaries.\n",
    ">\n",
    "\n",
    "- Note: This file will accept key-value pairs in other formats, but those represented here are the most common.\n",
    "\n",
    " > An example output file can be found within the [BIDS documentation](https://bids-specification.readthedocs.io/en/stable/modality-specific-files/electroencephalography.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6196304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating a specific parameter in the events JSON file\n",
    "json_file = Path(r'C:\\N8_internship_code\\bids_example\\sub-001\\eeg\\sub-001_task-rest_events.json').absolute()\n",
    "# Create BIDSPath using the JSON file's directory as root\n",
    "root = (r'C:\\N8_internship_code\\bids_example')\n",
    "\n",
    "\n",
    "bids_path1 = BIDSPath(subject='001', task='rest',\n",
    "                     suffix='events', extension='.json', datatype='eeg',\n",
    "                     root=root)\n",
    "\n",
    "entries = {# Nested dictionary for event duration containing description and units (1-level)\n",
    "        'Duration':{'Description': \"Duration of the event in seconds.\", 'Units': \"Seconds\"},\n",
    "         # Nested dictionary for trial type containing name, description, and levels (2-levels)\n",
    "        'TrialType':{'Name':\"Event Category\", \n",
    "                     'Description': \"Indicator of the type of action that is expected.\", \n",
    "                     'Levels': {\n",
    "                        'Start': \"A red square appears on the screen to indicate the start of a trial.\",\n",
    "                        'Stop': \"A green square appears on the screen to indicate the end of a trial\"}\n",
    "                     },\n",
    "         # Nested dictionary for stim file containing description, file type, and file path (1-level)\n",
    "        'Stim File': {'Description': \"File containing the stimulus presentation information for the event.\", 'FileType': \"CSV\", 'FilePath': \"sub-001_task-rest_stim.csv\"},\n",
    "        }     \n",
    "# Update the JSON file with your new entries  \n",
    "update_sidecar_json(bids_path1, entries, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e00c67e",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc08c08a",
   "metadata": {},
   "source": [
    "# File 7. Dataset Description\n",
    "Now we can move on to the more general, yet equally as important information files. \n",
    ">\n",
    "The code below will re-write the ENTIRE dataset description, overwriting any previous dataset description files.\n",
    "This file should describe the dataset in as much detail as possible, so you should attempt to include as much of the data outlined below as possible although BIDS only requires the presence of the 'necessary' information.\n",
    "\n",
    "#### BIDS components:\n",
    ">\n",
    "Necessary:\n",
    ">\n",
    "    1. StudyName\n",
    "    2. BIDSVersion \n",
    ">\n",
    "Recommended:\n",
    ">\n",
    "    3. HEDVersion\n",
    "    4. DatasetType\n",
    "    5. DataLicense\n",
    "    6. Authors\n",
    "    7. GeneratedBy\n",
    "        - Name\n",
    "        - Version\n",
    "        - Container\n",
    "        - Type\n",
    "        - Tag\n",
    "    8. SourceDatasets\n",
    ">\n",
    "Optional:\n",
    ">\n",
    "    9. Acknowledgements\n",
    "    10. HowToAcknowledge\n",
    "    11. Funding\n",
    "    12. EthicsApprovals\n",
    "    13. ReferencesAndLinks\n",
    "    14 Doi\n",
    "Note: `BIDS version` will be automatically included in the data file once the code is run.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cedf0fd",
   "metadata": {},
   "source": [
    "Once you have decided on the information you wish to include, you can append the code below, changing the information in quotation marks to your dataset's information.\n",
    ">\n",
    "Any that you don't intend on including should be written as `<item>=None`, just as `acknowledgements` is below. This will skip that item, preventing its inclusion in the file. \n",
    "> This code will overwrite any 'dataset description' file previously generated. This can be changed by changing `overwrite=True` to `overwrite=False`. \n",
    ">\n",
    "- Note: Doi must be written in the format: `doi:<insert_doi>`.\n",
    "\n",
    "> An example output file can be found within the [BIDS documentation](https://bids-specification.readthedocs.io/en/stable/modality-agnostic-files.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0769691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataset description JSON file\n",
    "# Will overwrite any existing dataset_description.json file in the root of the BIDS directory\n",
    "make_dataset_description(\n",
    "    path=bids_root,\n",
    "    name=\"EEGManyLabs Resting State Study\", \n",
    "    hed_version=\"1\",\n",
    "    dataset_type='raw',\n",
    "    data_license=\"CCO\",\n",
    "    authors=[\"Ariana Williams\", \"Daniel Brady\"],\n",
    "    generated_by=[\n",
    "        {\n",
    "            \"Name\": \"MNE-BIDS\",\n",
    "            \"Version\": \"0.14\",\n",
    "            \"Description\": \"Used to convert MEG data into BIDS format.\"\n",
    "        },\n",
    "        {\n",
    "            \"Name\": \"MNE-Python\",\n",
    "            \"Version\": \"1.6.1\",\n",
    "            \"Description\": \"Used for MEG preprocessing and analysis.\"\n",
    "        }\n",
    "    ],\n",
    "    source_datasets=[\n",
    "        {\n",
    "            \"URL\": \"https://example.com/source_dataset\",\n",
    "            \"DOI\": \"10.1234/example.doi\",\n",
    "        }],\n",
    "    acknowledgements=None,\n",
    "    how_to_acknowledge=\"Cite (Williams et al., 2025) when using this dataset\",\n",
    "    funding=[\"The NHS\", \"The Uk government\"],\n",
    "    ethics_approvals=\"Ethical approval was granted by the University of Leeds School of Psychology Ethics committee (12345 2025)\",\n",
    "    references_and_links=\"https://mne.tools/mne-bids/stable/whats_new_previous_releases.html\",\n",
    "    doi=\"doi:https://doi.org/10.1016/j.tins.2017.02.004\",\n",
    "            overwrite=True,\n",
    "            verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb89d296",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dfeaab",
   "metadata": {},
   "source": [
    "# File 8. Participants.tsv\n",
    "The participants.tsv file includes a table containing participant information relavant to the dataset. It is accompanied by the participants.json file, which provides more in-depth explanations for this information.\n",
    ">\n",
    "MNE-BIDS will automatically input the majority of this information, but you may wish to edit the file in order to add more columns to include further participant information.\n",
    "\n",
    "#### BIDS Components:\n",
    ">\n",
    "Necessary:\n",
    ">\n",
    "    1. Participant ID \n",
    ">\n",
    "Recommended:\n",
    ">\n",
    "    2. Species\n",
    "    3. Age\n",
    "    4. Sex\n",
    "    5. Handedness\n",
    "    6. Strain\n",
    "    7. Strain RRID\n",
    ">\n",
    "Optional:\n",
    ">\n",
    "    - Additional participant information may be included to further bolster your metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebd5922",
   "metadata": {},
   "source": [
    "## Manually updating the participants.tsv file:\n",
    "To edit this file, we must first edit the file path in the single quotation marks ('') to match the location of your `participants.tsv` file. \n",
    "\n",
    "This will ensure that the variable `participants_tsv` refers to the file we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b34d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the participants.tsv file to a variable\n",
    "participants_tsv = pd.read_csv(r'C:\\N8_internship_code\\bids_example\\participants.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a5ebf9",
   "metadata": {},
   "source": [
    "#### Adding/ Editing a column:\n",
    "\n",
    "Both of these functions can be managed using the same section of code!\n",
    "\n",
    "First, you should edit the 'Inputs' list to include the variables you wish to add to your new or pre-existing column. This should be done in participant order, beginning with the entry for the first participant in the file, and an entry must be submitted for each row.\n",
    "\n",
    "Then, you should change the text in double quotation marks (\"\") within `participants_tsv[\"__\"]`, to either title of the pre-existing column you wish to add to, or the title of the new column you wish to generate.\n",
    "\n",
    "Next, you should edit the file paths in the single quotation marks ('') to the location of your `participants.tsv` file, as we did above. This ensures that the code knows what file it's writing to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bbd995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing the desired inputs for the \"Education\" column\n",
    "Inputs = [\"High School\", \"A-level\", \"Bachelors\", \"PhD\"]  \n",
    "\n",
    "# Setting the rows in the \"Education\" column to the inputs listed above\n",
    "participants_tsv[\"Education\"] = Inputs\n",
    "\n",
    "# Writing the change to the file\n",
    "participants_tsv.to_csv(r'C:\\N8_internship_code\\bids_example\\participants.tsv', sep= '\\t', index=False, na_rep='n/a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9e7a3f",
   "metadata": {},
   "source": [
    "#### Editing one row:\n",
    " \n",
    "To edit a single row, you must use the `.loc` function, which allows us to select a row via it's label. In this case, we will use participant ID, by editing the participant ID number (in the second set of double quotation marks) to match that of the row you'd like to edit. \n",
    "\n",
    "From there, you can edit the column name to match the one you'd like to edit (in the third set of double quotation marks) and then the item you;d like to assign to the location (in the fourth set of double quotation marks).\n",
    "\n",
    "Then, after changing file location in the last line to match your own, we can write the changes to the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3821fba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Editing just one row in the participants.tsv file\n",
    "participants_tsv.loc[participants_tsv[\"participant_id\"] == \"sub-001\", \"Education\"] = \"none\"\n",
    "\n",
    "# Writing the change to the file\n",
    "participants_tsv.to_csv(r'C:\\N8_internship_code\\bids_example\\participants.tsv', sep= '\\t', index=False, na_rep='n/a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7bdcfb",
   "metadata": {},
   "source": [
    "#### Removing a row:\n",
    "\n",
    "To remove a row, you must use the `.drop` function, to which you assign an index, which is the number assigned to the row you wish to remove. \n",
    "Note: Indexes begin from 0, so the 'first' row will be #0, the 'second' row will be #1 and so on.\n",
    "\n",
    "Then, after the file location in the last line has been changed to match your own, we can write the changes to the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38ab43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing a row from the participants.tsv file using the row's index\n",
    "participants_tsv = participants_tsv.drop(index=1)\n",
    "\n",
    "# Writing the change to the file\n",
    "participants_tsv.to_csv(r'C:\\N8_internship_code\\bids_example\\participants.tsv', sep= '\\t', index=False, na_rep='n/a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d35d1ee",
   "metadata": {},
   "source": [
    "#### Adding a row:\n",
    "\n",
    "To add a row, you must first create a new data frame containing all of the columns and their values (in key:value pairs) that you want to add to the new row (do so by editing the text in the double quotation marks in the first line, and adding new key:value pairs where necessary). \n",
    "\n",
    "This will then be combined with the current data frame (participants_tsv), and once you have changed the file location in the last line to match your own, these edits can be written to the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4715ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new data frame for the new row\n",
    "new_participants_row = pd.DataFrame([{\"participant_id\": \"sub-002\", \"age\": 30, \"sex\":\"M\"}])\n",
    "\n",
    "# Combining the new row with the existing participants_tsv data frame\n",
    "participants_tsv = pd.concat([participants_tsv, new_participants_row], ignore_index=True)\n",
    "\n",
    "# Writing the change to the file\n",
    "participants_tsv.to_csv(r'C:\\N8_internship_code\\bids_example\\participants.tsv', sep= '\\t', index=False, na_rep='n/a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558ed33e",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61da025",
   "metadata": {},
   "source": [
    "# File 9. Participants.json\n",
    "The participants.json file exists as a counterpart to the participants.tsv file and is used to describe the TSV column names and the properties of their values, making interpretation easier, especially in the case of dataset-specific columns. \n",
    ">\n",
    "MNE-BIDS will automatically input the majority of this information, but you may wish to edit these descriptions to be more accurate, and should add additional descriptions for each new parameter added to the participants.tsv file (e.g. education level).\n",
    "\n",
    "#### BIDS Components:\n",
    ">\n",
    "Necessary:\n",
    ">\n",
    "    1. Participant ID \n",
    ">\n",
    "Recommended:\n",
    ">\n",
    "    2. Species\n",
    "    3. Age\n",
    "    4. Sex\n",
    "    5. Handedness\n",
    "    6. Strain\n",
    "    7. Strain RRID\n",
    ">\n",
    "Optional:\n",
    ">\n",
    "    - Additional participant information may be included to further bolster your metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dc4002",
   "metadata": {},
   "source": [
    "## Manually updating an element in the participants.json file: \n",
    ">\n",
    "To begin, you must edit the first line of code to match your file path `Path(r'___Your file path here___')`, and the second line to match your files directory `root = (r'__Your file directory here__')`.\n",
    "\n",
    "Once these are re-defined, you can update one or more aspect(s) of the sidecar using the `entries = {}` dictionary. This accepts `key:value` pairs, separated by colons (:), wherein single quotation marks ('') indicate a parameter name, while double quotation marks (\"\") indicate it's data entry.\n",
    ">\n",
    "##### The code below will display an example of a few formats the key-value pairs can present in, such as:\n",
    ">\n",
    "__Nested dictionary (1 level)__\n",
    "    - A key-value pair where the value is a dictionary containing key-value pairs.\n",
    ">\n",
    "__Nested dictionary (2+ levels)__\n",
    "    - A key-value pair where the value is a dictionary that contains one or more dictionaries.\n",
    "\n",
    "- Note: This file will accept key-value pairs in other formats, but those represented here are the most common.\n",
    "\n",
    "> An example output file can be found within the [BIDS documentation](https://bids-specification.readthedocs.io/en/stable/modality-agnostic-files.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165f78cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for adding information to the participants.json file\n",
    "json_file = Path(r'C:\\N8_internship_code\\bids_example\\participants.json').absolute()\n",
    "# Create BIDSPath using the JSON file's directory as root\n",
    "root = (r'C:\\N8_internship_code\\bids_example')\n",
    "\n",
    "\n",
    "bids_path1 = BIDSPath(subject=None, task=None,\n",
    "                     suffix='participants', extension='.json', datatype=None,\n",
    "                     root=root)\n",
    "\n",
    "entries = { # Nested dictionary for age containing description and units (1-level)\n",
    "            'Age': {'Description': \"Age of the participant at time of testing\", 'Units': \"Years\"}, \n",
    "            # Nested dictionary for handedness containing description and levels (2-levels)\n",
    "            'Handedness': {'Description': \"Handedness of the participant\",\n",
    "                        'Levels': {\n",
    "                            \"R\": \"Right-handed\",\n",
    "                            \"L\": \"Left-handed\",\n",
    "                            \"A\": \"Ambidextrous\"\n",
    "                        }\n",
    "                },\n",
    "        }       \n",
    "update_sidecar_json(bids_path1, entries, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19460a4d",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b010fcf",
   "metadata": {},
   "source": [
    "# 10. Phenotype file\n",
    "https://bids-specification.readthedocs.io/en/stable/modality-agnostic-files.html#phenotypic-and-assessment-data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cfd456",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ee5b47",
   "metadata": {},
   "source": [
    "# How to cite MNE-BIDS\n",
    "\n",
    "#### As we used their tools to generate our BIDS formatted dataset, we must cite MNE-BIDS somewhere within it!\n",
    "The following code will automatically do this for you:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980bca8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "readme = op.join(bids_root, \"README\")\n",
    "with open(readme, encoding=\"utf-8-sig\") as fid:\n",
    "    text = fid.read()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de753fcd",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede764c4",
   "metadata": {},
   "source": [
    "# Our Citations\n",
    "MNE-BIDS\n",
    "> Appelhoff, S., Sanderson, M., Brooks, T., Vliet, M., Quentin, R., Holdgraf, C., Chaumon, M., Mikulan, E., Tavabi, K., Höchenberger, R., Welke, D., Brunner, C., Rockhill, A., Larson, E., Gramfort, A., & Jas, M. (2019). MNE-BIDS: Organizing electrophysiological data into the BIDS format and facilitating their analysis. Journal of Open Source Software, 4:1896. DOI: 10.21105/joss.01896\n",
    ">\n",
    ">  Pernet, C.R., Appelhoff, S., Gorgolewski, K.J. et al. EEG-BIDS, an extension to the brain imaging data structure for electroencephalography. Sci Data 6, 103 (2019). https://doi.org/10.1038/s41597-019-0104-8\n",
    ">\n",
    "MNE-Python\n",
    "> Alexandre Gramfort, Martin Luessi, Eric Larson, Denis A. Engemann, Daniel Strohmeier, Christian Brodbeck, Roman Goj, Mainak Jas, Teon Brooks, Lauri Parkkonen, and Matti S. Hämäläinen. MEG and EEG data analysis with MNE-Python. Frontiers in Neuroscience, 7(267):1–13, 2013. doi:10.3389/fnins.2013.00267.\n",
    ">\n",
    "BIDS\n",
    "> Gorgolewski, K.J., Auer, T., Calhoun, V.D., Craddock, R.C., Das, S., Duff, E.P., Flandin, G., Ghosh, S.S., Glatard, T., Halchenko, Y.O., Handwerker, D.A., Hanke, M., Keator, D., Li, X., Michael, Z., Maumet, C., Nichols, B.N., Nichols, T.E., Pellman, J., Poline, J.-B., Rokem, A., Schaefer, G., Sochat, V., Triplett, W., Turner, J.A., Varoquaux, G., Poldrack, R.A. (2016). The brain imaging data structure, a format for organizing and describing outputs of neuroimaging experiments. Scientific Data, 3 (160044). doi:10.1038/sdata.2016.44\n",
    ">\n",
    ">  Pernet, C. R., Appelhoff, S., Gorgolewski, K.J., Flandin, G., Phillips, C., Delorme, A., Oostenveld, R. (2019). EEG-BIDS, an extension to the brain imaging data structure for electroencephalography. Scientific data, 6 (103). doi:10.1038/s41597-019-0104-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea777d3",
   "metadata": {},
   "source": [
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
