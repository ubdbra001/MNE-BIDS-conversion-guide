{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62056a25",
   "metadata": {},
   "source": [
    "# MNE-BIDS pipeline\n",
    ">\n",
    "#### This document will serve as a step-by-step guide to walk you through transforming your EEG dataset into one compliant with the BIDS format, using MNE-BIDS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28eba06a",
   "metadata": {},
   "source": [
    "### What is MNE?\n",
    "> MNE is an open source python package for working with EEG and MEG data, which serves to facilitate the exploration, visualisation and analysis of neuroimaging data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eca1136",
   "metadata": {},
   "source": [
    "### What is BIDS?\n",
    "> BIDS (Brain Imaging Data Structure) is a simple method of organising neuroimaging data that is easy to adopt and promotes standardisation across neuroimaging experiments. This allows for easier, more open data sharing and collaboration.\n",
    ">\n",
    "> It involves a hierarchical folder organisation structure, with four main levels:\n",
    ">\n",
    "\n",
    "project/\n",
    "\n",
    "--> subject\n",
    "\n",
    "---->  session\n",
    "\n",
    "------> datatype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45baf688",
   "metadata": {},
   "source": [
    "## SO, MNE-BIDS...?\n",
    "> Is a processing pipeline that uses MNE-python tools to generate BIDS compliant datasets!\n",
    ">\n",
    "If you don't currently have MNE-BIDS installed, please refer to their official [website](https://mne.tools/mne-bids-pipeline/stable/getting_started/install.html) to do so before beginning this walkthrough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5588cc48",
   "metadata": {},
   "source": [
    "# What versions will this document use?\n",
    "\n",
    "#### - MNE version: 1.9.0\n",
    "#### - BIDS version: 1.10.0\n",
    "#### - MNE-BIDS version: 0.16.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc508c83",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2866c154",
   "metadata": {},
   "source": [
    "# Expected Proficiencies\n",
    "> #### Prior to using this pipeline, a certain level of understanding/ skill is expected. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e572f6dd",
   "metadata": {},
   "source": [
    "This entails:\n",
    "- Some knowledge of python (to understand and implement the present code), although this will be explained throughout.\n",
    "- An understanding of what a BIDS formatted dataset should include and how it should look (for checking the dataset has converted correctly).\n",
    "  > This information can be found on the [BIDS website](https://bids.neuroimaging.io/getting_started/index.html).\n",
    "- Familiarity with your EEG dataset and its associated metadata (to ensure all important information is present post-conversion and add any that is missing)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b96f5df",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481f30e7",
   "metadata": {},
   "source": [
    "# 1. Downloading data\n",
    "> #### Collecting the EEG dataset necessary to run through this pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb325c6",
   "metadata": {},
   "source": [
    "In order to complete this pipeline, you will first need some EEG data. If you intend to run this pipeline using your pre-existing dataset, you can simply move onto the next step. If you don't have any EEG data to test this process on, we suggest downloading the [EEG Motor Movement/Imagery Dataset](https://physionet.org/content/eegmmidb/1.0.0/) from the [Physiobank Database](https://physionet.org/data/). This document will use this as example data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd2b600",
   "metadata": {},
   "source": [
    "GIVE LINK TO DOWNLOAD FULL CODE FROM DOC just like MNE does [At bottom]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c438d4",
   "metadata": {},
   "source": [
    "# 2. Data formatting\n",
    "> #### This pipeline's data format expectations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28464a6e",
   "metadata": {},
   "source": [
    "This pipeline is curated to work with EDF (European Data Format) formatted datasets, however MNE is capable of handling a variety of formats. \n",
    ">  If your data is currently in a different format, you will need to use a slightly different section of code when reading in your data (step 6). For guidance on this, refer to MNE's documentation on [importing data from EEG devices](https://mne.tools/stable/auto_tutorials/io/20_reading_eeg_data.html#sphx-glr-auto-tutorials-io-20-reading-eeg-data-py) for guidance. \n",
    ">\n",
    "The pipeline will also write the dataset into the EDF format in step 7 as recommended by BIDS. If you require a different output format, you may edit the `format` parameter of `write_raw_bids` using [MNE's guidance](https://mne.tools/mne-bids/stable/generated/mne_bids.write_raw_bids.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3bc51d",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a62ce0",
   "metadata": {},
   "source": [
    "# 3. Importing the necessary tools\n",
    ">### To begin, we will need to import all the tools necessary for converting the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc978cc5",
   "metadata": {},
   "source": [
    "This first section of code will import tools that allow us to work with the file paths and simplify the method of handling them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa3095e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Allows us to work with file paths\n",
    "import os.path as op\n",
    "#Makes file path handling simpler\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222527de",
   "metadata": {},
   "source": [
    "Next, we need to `import MNE`, a python package for working with EEG and MEG data, and some associated tools that we will use here. \n",
    ">\n",
    "From `mne_bids`, we are importing:\n",
    "- `BIDSPath`:\n",
    "A tool for creating a BIDS formatted file path\n",
    "- `print_dir_tree`:\n",
    "A tool for presenting the contents of a folder in a 'tree' view\n",
    "- `write_raw_bids`:\n",
    "A tool for saving EEG data into BIDS format\n",
    ">\n",
    "Additionally, we wil be installing MNE-BIDS using [pip](https://pypi.org/project/pip/) (a package installer), before ensuring that MNE-BIDS is upgraded to be the newest version, to allow smooth functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8117ec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "%pip install mne_bids\n",
    "%pip install --upgrade mne_bids\n",
    "\n",
    "from mne_bids import BIDSPath, print_dir_tree, write_raw_bids, make_dataset_description, update_sidecar_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c40bee",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd272f5d",
   "metadata": {},
   "source": [
    "# 4. Finding the data\n",
    ">### After completing our imports, we need to find the EEG data files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fbeb4d",
   "metadata": {},
   "source": [
    "In the code below, the first line specifies where the folders and sub-folders for the data can be found. These should include your EEG data and any additional information (metadata). \n",
    ">\n",
    "You should modify this to include your own file pathway: `data_dir = Path(r\"___your file pathway____\")`. This should be the file containing your task files, or the highest file level containing your dataset and no external (dataset-unrelated) files.\n",
    "> Here, the `r` (raw) ensures the file location is read as is, and that the backslashes don't get interpreted as special characters, so don't break up the text.\n",
    ">\n",
    "The line below this prints a visualisation of the first sub-folders within (using the `print_dir_tree` tool!). \n",
    "> You may have 1 or more of these, depending on how much EEG data you wish to make BIDS compliant. Each of these should contain EEG data from one specific task type, including data from each participant and any associated metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069ad766",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the file path to your data's location\n",
    "data_dir = Path(r\"C:\\N8_internship_code\\Motor_Imaging_Dataset\")\n",
    "print_dir_tree(data_dir, max_depth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0500035",
   "metadata": {},
   "source": [
    "This next section lists the file paths for the sub-folders we just visualised and adds them to the list 'children'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab5a02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "children = [child for child in data_dir.iterdir()]\n",
    "children"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cef6ebe",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35b5456",
   "metadata": {},
   "source": [
    "# 5. Selecting specific files\n",
    ">### Let's specify the files we want to use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fd7eb1",
   "metadata": {},
   "source": [
    "Here, the first line serves to identify which of the two files we want to write into BIDS format (note: in python, the first index is given a value of 0). If you have multiple files, each time you run through this you should change the number at the end to match the file you are wanting to adapt. \n",
    ">\n",
    "The second line lists all the files in the specified subfolder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8554874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change this to match the file number\n",
    "dir_number = 5\n",
    "files = [file for file in children[dir_number].iterdir()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1342cd1",
   "metadata": {},
   "source": [
    "This sets the first file in the folder to the variable `file_path`, then prints this. \n",
    ">\n",
    "Even when completing multiple iterations (for more than one dataset), the value should NOT be changed from 0!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da3668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = files[1]\n",
    "file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bffe158",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932801a0",
   "metadata": {},
   "source": [
    "# 6. Reading/ specifying the data\n",
    ">### Now we've completed our preparations, lets compile our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae205c9",
   "metadata": {},
   "source": [
    "Here, we are reading the EEG data from the previously selected file path to the `data` variable.\n",
    ">\n",
    "As previously mentioned, the current code is tailored to EEGLab formatted datasets and won't work with any other formats. As such, you must use a slightly different line of code depending on the format of your data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b896a11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mne.io.read_raw_edf(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d40778",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ecfb8e",
   "metadata": {},
   "source": [
    "### In this section we will also specify some important metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37101bce",
   "metadata": {},
   "source": [
    "This process will involve writing information to the 'info' dictionary, which holds all of the metadata for the dataset. Not all aspects of this can be written to, but a few can.\n",
    "\n",
    "So first, we need to import a few extra tools to help with this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be2531d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb0681c",
   "metadata": {},
   "source": [
    "Next, fill in the value section of the `key:value` pairs below to match the datset's information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f99efe7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bad channel(s) ['C3', 'F3'] marked do not exist in info",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[93], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m data\u001b[38;5;241m.\u001b[39minfo[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mline_freq\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# A list of 'bad' (noisy or broken) channels, by name\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC3\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF3\u001b[39m\u001b[38;5;124m\"\u001b[39m ]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# A description of the recording\u001b[39;00m\n\u001b[0;32m     16\u001b[0m data\u001b[38;5;241m.\u001b[39minfo[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA motor imaging dataset...\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Ariana\\Lib\\site-packages\\mne\\_fiff\\meas_info.py:960\u001b[0m, in \u001b[0;36mValidatedDict.__setitem__\u001b[1;34m(self, key, val)\u001b[0m\n\u001b[0;32m    958\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attributes[key])\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 960\u001b[0m         val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attributes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\n\u001b[0;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# attribute checker function\u001b[39;00m\n\u001b[0;32m    963\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    964\u001b[0m     class_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Ariana\\Lib\\site-packages\\mne\\_fiff\\meas_info.py:1147\u001b[0m, in \u001b[0;36m_check_bads\u001b[1;34m(bads, info)\u001b[0m\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_bads\u001b[39m(bads, \u001b[38;5;241m*\u001b[39m, info):\n\u001b[1;32m-> 1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMNEBadsList\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ariana\\Lib\\site-packages\\mne\\_fiff\\meas_info.py:1121\u001b[0m, in \u001b[0;36mMNEBadsList.__init__\u001b[1;34m(self, bads, info)\u001b[0m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, bads, info):\n\u001b[1;32m-> 1121\u001b[0m     \u001b[43m_check_bads_info_compat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mne_info \u001b[38;5;241m=\u001b[39m info\n\u001b[0;32m   1123\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(bads)\n",
      "File \u001b[1;32mc:\\Users\\Ariana\\Lib\\site-packages\\mne\\_fiff\\meas_info.py:1114\u001b[0m, in \u001b[0;36m_check_bads_info_compat\u001b[1;34m(bads, info)\u001b[0m\n\u001b[0;32m   1112\u001b[0m missing \u001b[38;5;241m=\u001b[39m [bad \u001b[38;5;28;01mfor\u001b[39;00m bad \u001b[38;5;129;01min\u001b[39;00m bads \u001b[38;5;28;01mif\u001b[39;00m bad \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mch_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m   1113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1114\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbad channel(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m marked do not exist in info\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: bad channel(s) ['C3', 'F3'] marked do not exist in info"
     ]
    }
   ],
   "source": [
    "# Information about the EEG headset\n",
    "data.info[\"device_info\"] = {\n",
    "    \"type\": __,\n",
    "    \"model\": \"_\",\n",
    "    \"serial\": \"_\",\n",
    "    \"site\": \"_\"\n",
    "    }\n",
    "\n",
    "# The line frequency of the data (in hertz)\n",
    "data.info[\"line_freq\"] = 50\n",
    "\n",
    "# A list of 'bad' (noisy or broken) channels, by name\n",
    "data.info[\"bads\"] = [\"_\"]\n",
    "\n",
    "# A description of the recording\n",
    "data.info[\"description\"] = \"A motor imaging dataset...\"\n",
    "\n",
    "# The name of the experimenter\n",
    "data.info[\"experimenter\"] = \"John Doe\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8456dfc6",
   "metadata": {},
   "source": [
    "Then, enter in the required information for the subject info sction using the same method. \n",
    "\n",
    "If the participant's birthdate is unknown, this can be calculated by inputting the date of measurement (YYYY/M/D) into the first line of code, then inputting the participant's age into the third line (years=___). The variable 'birthdate' can then be inputted as the value for the \"birthday\" variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5db2545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates the (approx) birthdate of the participant based on the measurement date and age\n",
    "data.set_meas_date(datetime(2015, 6, 7, tzinfo= timezone.utc))\n",
    "recording_date = data.info[\"meas_date\"]\n",
    "Birthdate = recording_date - relativedelta(years=30)\n",
    "\n",
    "data.info[\"subject_info\"] = {\n",
    "    \"id\": 1,\n",
    "    \"his_id\": \"sub-001\",\n",
    "    \"last_name\": \"Doe\",\n",
    "    \"first_name\": \"John\",\n",
    "    \"middle_name\": \"A\",\n",
    "    \"birthday\": Birthdate,\n",
    "    \"sex\": 2,\n",
    "    \"hand\": 1,\n",
    "    \"weight\": 70.0,\n",
    "    \"height\": 175.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8103ed88",
   "metadata": {},
   "source": [
    "For some, the helium levels of your device will be of importance. If so, you should also set the value in these key:value pairs to match your information. \n",
    "> Note: To set the meas_date, change the numbers to your date of measurement (YYYY/M/D)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f89f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information about the device helium, if applicable\n",
    "data.info[\"helium_info\"] = {\n",
    "    \"he_level_raw\": 20,\n",
    "    \"helium_level\": 12,\n",
    "    \"orig_file_guid\": \"_\",\n",
    "    \"meas_date\": (datetime(2015, 6, 7, tzinfo= timezone.utc))\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d0a64a",
   "metadata": {},
   "source": [
    "Finally, we will be inputting the montage for your dataset.\n",
    "\n",
    "The below code will list the standard montages that MNE-BIDS supports. From these, you should select the montage that applies to your dataset.\n",
    "\n",
    "MNE also supports the creation of your own dataset. Those that require this function may benefit from following MNE's guidelines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f15f069",
   "metadata": {},
   "outputs": [],
   "source": [
    "builtin_montages = mne.channels.get_builtin_montages(descriptions=True)\n",
    "for montage_name, montage_description in builtin_montages:\n",
    "    print(f\"{montage_name}: {montage_description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86eac716",
   "metadata": {},
   "source": [
    "Next, you can input your montage name within the double quotation marks below to display it's information and visualise it as both a 2D and 3D plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f136e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_montage = mne.channels.make_standard_montage(\"biosemi64\")\n",
    "\n",
    "# Printing montage information\n",
    "print(my_montage)\n",
    "\n",
    "# Viualising montage in 2D\n",
    "my_montage.plot()\n",
    "\n",
    "# Visualising montage in 3D\n",
    "fig = my_montage.plot(kind=\"3d\", show=False)  # 3D\n",
    "fig = fig.gca().view_init(azim=70, elev=15)  # set view angle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dfe45d",
   "metadata": {},
   "source": [
    "If you are happy with these visualisations, the montage can be written to the data using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9a0e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_montage(my_montage, match_case=True, match_alias=False, on_missing='ignore', verbose=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd970fd",
   "metadata": {},
   "source": [
    "This next section of code will create a new folder path for storing EEG data in BIDS format, then prints it out. \n",
    ">\n",
    "We recommend renaming your file to something more specific to your dataset, by switching out the text in the quotation marks. Attempt to avoiding using any spaces in the title to prevent possible later complications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed8d54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bids_root = op.join(data_dir.parent, \"Motor_Imaging_Example\")\n",
    "bids_root"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53eaa835",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c23650",
   "metadata": {},
   "source": [
    "# 7. Writing the data\n",
    "> #### Let's write our selected data into BIDS format!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54eae464",
   "metadata": {},
   "source": [
    "First, you should manually define the partricipant number/ subject id and task name for this dataset, setting them each to a variable as seen in the first two rows.\n",
    ">\n",
    "Then, using the `BIDSPath` tool we imported earlier, we will assign the subject, task and the folder path we just created to `bids_path`. \n",
    ">\n",
    "We will then use another imported tool, `write_raw_bids` to write the data (from the file path we defined earlier) into the new file path we created, linking it to the subject id and task type we outlined. The desired format of the output data is also outlined here `format=\"EEGLAB\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569683cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Edit this information to match your data\n",
    "subject_id = \"S001\"\n",
    "task = \"task1\"\n",
    "\n",
    "bids_path = BIDSPath(subject=subject_id, task=task, root=bids_root)\n",
    "write_raw_bids(data, bids_path, overwrite=True, allow_preload=True, format=\"EDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe4597c",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c9b874",
   "metadata": {},
   "source": [
    "### Now you have formatted your dataset to BIDS standards! \n",
    "#### Don't forget to repeat steps 4 and 5 for all of the file paths we found in step 3\n",
    ">\n",
    "## But hold on!\n",
    "#### Your BIDS formatted dataset isn't quite complete yet..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a65353b",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f10e503",
   "metadata": {},
   "source": [
    "# Editing and checking your BIDS formatted dataset\n",
    "### The steps below will walk you through finding and editing some of the files in your new dataset, in order to make them BIDS-compliant. \n",
    "Each of these files should automatically include a large amount of information derived from your dataset and stored in BIDS format, however this may not always be completely accurate.\n",
    ">\n",
    "As such, the next steps will walk you through checking that your BIDS dataset is accurate, and how to adapt these files if necessary. Some of the file's items will be deemed required for a BIDS-compliant dataset, while others are recommended or merely optional. You __MUST__ ensure that the required elements are present and have correct data, and although not necessary, it will be beneficial for you to include as much additional data as possible, especially if it is important information for your dataset.\n",
    "\n",
    "> Don't forget to do these checks for all task types (all of the file pathways we found)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1999b7d4",
   "metadata": {},
   "source": [
    "You can do this by navigating to the file path we assigned to the variable `bids_root` in step 4, then working through all of the files and investigating what is present/correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3ecd93",
   "metadata": {},
   "source": [
    "# Editing different file formats\n",
    "Some of the following files will follow the .json format (Sidecar, Coordinate System, Dataset Description), others (Channels Description, Electrodes description) will be in the .tsv format, and a few will have a file in each format (Events, Participants).\n",
    "\n",
    "These file types are each edited via slightly different methods, so while .json files require no extra imports, to edit our .tsv files we must import the [pandas](https://pandas.pydata.org/pandas-docs/version/1.4/index.html) library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e82cb5",
   "metadata": {},
   "source": [
    "Due to the differences in their display formats (text vs tabular), while .json files can be edited using a simple dictionary of key:value pairs, editing .tsv files requires a few different code functions. \n",
    "\n",
    "Those outlined in this document will walk you through:\n",
    "- Adding/ Editing a column\n",
    "- Editing the value of just one row\n",
    "- Removing a row\n",
    "- Adding a row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c5dcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the pandas library to edit .tsv files\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0828cf",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bed1f56",
   "metadata": {},
   "source": [
    "To ensure our next sections of code are as clean and easy to use as possible, we will be assigning key file pathway roots to variables. Later in the document we will use these to create file pathways to specific file locations.\n",
    "\n",
    "Here, you should:\n",
    "- Set the variable 'root' to the top-level folder of the BIDS dataset \n",
    "- Set the variable 'eeg_root' to the folder containing eeg data for the current subject\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23cf5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set 'root' to the top-level folder of the BIDS dataset \n",
    "root = Path(r'c:\\N8_internship_code\\Motor_Imaging_Example')\n",
    "\n",
    "# Set 'eeg_root' to the folder containing eeg data for the current subject\n",
    "eeg_root = Path(r'C:\\N8_internship_code\\Motor_Imaging_Example\\sub-S001\\eeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c7799c",
   "metadata": {},
   "source": [
    "# Dataset Description\n",
    "> Edits to this file are incredibly important, as this outlines\n",
    " all of the general information about your dataset.\n",
    ">\n",
    "The code below will re-write the ENTIRE dataset description, overwriting any previous dataset description files.\n",
    "This file should describe the dataset in as much detail as possible, so you should attempt to include as much of the data outlined below as possible although BIDS only requires the presence of the 'necessary' information.\n",
    "\n",
    "#### BIDS components:\n",
    ">\n",
    "Necessary:\n",
    ">\n",
    "    1. StudyName\n",
    "    2. BIDSVersion \n",
    ">\n",
    "Recommended:\n",
    ">\n",
    "    3. HEDVersion\n",
    "    4. DatasetType\n",
    "    5. DataLicense\n",
    "    6. Authors\n",
    "    7. GeneratedBy\n",
    "        - Name\n",
    "        - Version\n",
    "        - Container\n",
    "        - Type\n",
    "        - Tag\n",
    "    8. SourceDatasets\n",
    ">\n",
    "Optional:\n",
    ">\n",
    "    9. Acknowledgements\n",
    "    10. HowToAcknowledge\n",
    "    11. Funding\n",
    "    12. EthicsApprovals\n",
    "    13. ReferencesAndLinks\n",
    "    14 Doi\n",
    "Note: `BIDS version` will be automatically included in the data file once the code is run.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1056b7",
   "metadata": {},
   "source": [
    "Once you have decided on the information you wish to include, you can append the code below, changing the information in quotation marks to your dataset's information.\n",
    ">\n",
    "Any that you don't intend on including should be written as `<item>=None`, just as `acknowledgements` is below. This will skip that item, preventing its inclusion in the file. \n",
    "> This code will overwrite any 'dataset description' file previously generated. This can be changed by changing `overwrite=True` to `overwrite=False`. \n",
    ">\n",
    "- Note: Doi must be written in the format: `doi:<insert_doi>`.\n",
    "\n",
    "> An example output file can be found within the [BIDS documentation](https://bids-specification.readthedocs.io/en/stable/modality-agnostic-files.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ebb7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'C:\\N8_internship_code\\Motor_Imaging_Example\\dataset_description.json'...\n"
     ]
    }
   ],
   "source": [
    "# Creating a dataset description JSON file\n",
    "# Will overwrite any existing dataset_description.json file in the root of the BIDS directory\n",
    "make_dataset_description(\n",
    "    path=bids_root,\n",
    "    name=\"EEG Motor Movement/ Imagery Dataset\", \n",
    "    hed_version=\"1\",\n",
    "    dataset_type='raw',\n",
    "    data_license=\"CCO\",\n",
    "    authors=[\"John Doe\", \"Jane Doe\"],\n",
    "    generated_by=[\n",
    "        {\n",
    "            \"Name\": \"MNE-BIDS\",\n",
    "            \"Version\": \"0.14\",\n",
    "            \"Description\": \"Used to convert MEG data into BIDS format.\"\n",
    "        },\n",
    "        {\n",
    "            \"Name\": \"MNE-Python\",\n",
    "            \"Version\": \"1.6.1\",\n",
    "            \"Description\": \"Used for MEG preprocessing and analysis.\"\n",
    "        }\n",
    "    ],\n",
    "    source_datasets=[\n",
    "        {\n",
    "            \"URL\": \"https://example.com/source_dataset\",\n",
    "            \"DOI\": \"10.1234/example.doi\",\n",
    "        }],\n",
    "    acknowledgements=None,\n",
    "    how_to_acknowledge=\"Cite (Doe et al., 2025) when using this dataset\",\n",
    "    funding=[\"The NHS\", \"The Uk government\"],\n",
    "    ethics_approvals=\"Ethical approval was granted by the University of ___ School of Psychology Ethics committee\",\n",
    "    references_and_links=\"https://mne.tools/mne-bids/stable/whats_new_previous_releases.html\",\n",
    "    doi=\"doi:https://doi.org/10.1016/j.tins.2017.02.004\",\n",
    "            overwrite=True,\n",
    "            verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2770038",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14e2378",
   "metadata": {},
   "source": [
    "# Sidecar JSON\n",
    ">\n",
    "This file's name should have a naming format simlilar to *_eeg.json in your 'eeg' subfolder. \n",
    "\n",
    "Once you have located the file, you should open it and look through its variables. Below is a list of information BIDS needs/suggests for this file. \n",
    "> Take note of any elements that are missing/incorrect; these can be updated using the next section of code.\n",
    ">\n",
    "#### BIDS components:\n",
    ">\n",
    "Necessary:\n",
    ">\n",
    "    1. EEGReference\n",
    "    2. SamplingFrequency\n",
    "    3. PowerlineFrequency\n",
    "    4. SoftwareFilters\n",
    "    5. TaskName\n",
    ">\n",
    "Recommended:\n",
    ">\n",
    "    6. TaskDescription\n",
    "    7. Instructions\n",
    "    8. CogAtlasID\n",
    "    9. CogPOID\n",
    "    10. CapManufacturer\n",
    "    11. CapManufacturer'sModelName\n",
    "    12. SoftwareVersions\n",
    "    13. DeviceSerialNumber\n",
    "    14. EEGChannelCount\n",
    "    15. ECGChannelCount\n",
    "    16. EMGChannelCount\n",
    "    17. EOGChannelCount\n",
    "    18. MISCChannelCount\n",
    "    19. TriggerChannelCount\n",
    "    20. RecordingDuration\n",
    "    21. RecordingType\n",
    "    22. EpochLength\n",
    "    23. EEGGround\n",
    "    24. HeadCircumference\n",
    "    25. EEGPlacementScheme\n",
    "    26. HardwareFilters\n",
    "    27. SubjectArtefactDescription\n",
    "    28. InstitutionName\n",
    "    29. InstitutionAddress\n",
    "    30. InstitutionalDepartment Name\n",
    ">\n",
    "Optional:\n",
    ">\n",
    "    31. ElectricalStimulation\n",
    "    32. ElectricalStimulationParameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c269e8be",
   "metadata": {},
   "source": [
    "## Manually updating an element in the JSON file. \n",
    ">\n",
    "To begin, you must edit the first line of code to include your sidecar file's name in the double quotation marks (\"\"). This will be combined with 'eeg_root' to set your file pathway. Additionally, you must change the `subject=` and `task=` sections of `bids_path1` to match your dataset's file name.\n",
    "\n",
    "Once these are re-defined, you can update one or more aspect(s) of the sidecar using the `entries = {}` dictionary. This accepts `key:value` pairs, separated by colons (:), wherein single quotation marks ('') indicate a variable name, while double quotation marks (\"\") indicate it's data entry.\n",
    ">\n",
    "##### The code below will display an example of a few formats the key-value pairs can present in, such as:\n",
    "__Numerical__\n",
    "    - A key-value pair where the value is a number (int/float).\n",
    ">\n",
    "__Written__\n",
    "    - A key-value pair where the value is a string (text).\n",
    ">\n",
    "__Nested dictionary (1 level)__\n",
    "    - A key-value pair where the value is a dictionary containing key-value pairs.\n",
    ">\n",
    "__Nested dictionary (2+ levels)__\n",
    "    - A key-value pair where the value is a dictionary that contains one or more dictionaries.\n",
    ">\n",
    "\n",
    " > An example output file can be found within the [BIDS documentation](https://bids-specification.readthedocs.io/en/stable/modality-specific-files/electroencephalography.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b337b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#updating a specific item in the sidecar JSON file\n",
    "sidecar_file = Path(eeg_root / \"sub-S001_task-task1_eeg.json\").absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc49e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bids_path1 = BIDSPath(subject='001', task='rest',\n",
    "                     suffix='eeg', extension='.json', datatype='eeg',\n",
    "                     root=root)\n",
    "\n",
    "entries = {# Simple key-value pair for head circumference (numerical)\n",
    "           'HeadCircumference': 58.0,\n",
    "           # Simple key-value pair for manufacturer model name (written)\n",
    "            'ManufacturersModelName':\"Brain Products actiCHamp\",\n",
    "            # Nested dictionary for software versions (1-level)\n",
    "            'SoftwareVersions' : {\n",
    "                'MNE': \"1.9.0\",\n",
    "                'BIDS': \"1.10.0\",\n",
    "                'MNE-BIDS': \"0.16.0\"\n",
    "                },\n",
    "           # Nested dictionary for software filters (2-levels)\n",
    "           'SoftwareFilters': {\n",
    "                \"Anti-aliasing filter\":{\n",
    "                \"half-amplitude cutoff (Hz)\": 500,\n",
    "                \"Roll-off\": \"6dB/Octave\"\n",
    "                }\n",
    "                },\n",
    "            }   \n",
    "\n",
    "# Update the JSON file with your new entries\n",
    "update_sidecar_json(bids_path1, entries, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca242e97",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9172f231",
   "metadata": {},
   "source": [
    "# Channels Description TSV\n",
    ">\n",
    "This should have a format simlilar to *_channels.tsv in your 'eeg' subfolder. \n",
    "\n",
    "Once you have located the file, you should open it and look through the components it lists. Below is a list of information BIDS needs/suggests for this file. Take note of which elemets are missing or incorrect.\n",
    ">\n",
    "#### BIDS components:\n",
    ">\n",
    "Necessary:\n",
    ">\n",
    "    1. Name\n",
    "    2. Type\n",
    "    3. Units\n",
    "Recommended\n",
    ">\n",
    "    n/a\n",
    ">\n",
    "Optional:\n",
    ">\n",
    "    4. Description\n",
    "    5. SamplingFrequency\n",
    "    6. Reference\n",
    "    7. LowCutoff\n",
    "    8. HighCutoff\n",
    "    9. Notch\n",
    "    10. Status\n",
    "    11. StatusDescription"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a55044",
   "metadata": {},
   "source": [
    "## Manually updating the channels.tsv file:\n",
    "To edit this file, we must first edit the double quotation marks (\"\") to match the full name of your `channels.tsv` file, which will be combined with 'eeg_root' to create the file path. \n",
    "\n",
    "This will ensure that the variable `channels_tsv` refers to the file we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d09e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_path = eeg_root / \"sub-S001_task-task1_channels.tsv\"\n",
    "# Assigning the channels.tsv file to a variable\n",
    "channels_tsv = pd.read_csv(channels_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be963ea",
   "metadata": {},
   "source": [
    "#### Adding/ Editing a column:\n",
    "\n",
    "Both of these functions can be managed using the same section of code!\n",
    "\n",
    "First, you should edit the 'Inputs' list to include the variables you wish to add to your new or pre-existing column. This should be done in channel order, beginning with the entry for the first channel in the file, and an entry must be submitted for each row.\n",
    "\n",
    "Then, you should change the text in double quotation marks (\"\") within `channels_tsv[\"__\"]`, to either title of the pre-existing column you wish to add to, or the title of the new column you wish to generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53609125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing the desired inputs for the \"status\" column\n",
    "Inputs = [\"Good\", \"Bad\", \"Average\"]  \n",
    "\n",
    "# Setting the rows in the \"status\" column to the inputs listed above\n",
    "channels_tsv[\"status\"] = Inputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd75cfe2",
   "metadata": {},
   "source": [
    "#### Editing one row:\n",
    " \n",
    "To edit a single row, you must use the `.loc` function, which allows us to select a row via it's label. In this case, we will use 'name', by editing the name of the channel (in the second set of double quotation marks) to match that of the row you'd like to edit. \n",
    "\n",
    "From there, you can edit the column name to match the one you'd like to edit (in the third set of double quotation marks) and then the item you'd like to assign to the location (in the fourth set of double quotation marks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2412504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Editing just one row in the channels.tsv file\n",
    "channels_tsv.loc[channels_tsv[\"name\"] == \"Fp1\", \"status\"] = \"good\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a92daf8",
   "metadata": {},
   "source": [
    "#### Removing a row:\n",
    "\n",
    "To remove a row, you must use the `.drop` function, to which you assign an index, which is the number assigned to the row you wish to remove. \n",
    "> Note: Indexes begin from 0, so the 'first' row will be #0, the 'second' row will be #1 and so on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b866f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing a row from the channels.tsv file using the row's index\n",
    "channels_tsv = channels_tsv.drop(index=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32362096",
   "metadata": {},
   "source": [
    "#### Adding a row:\n",
    "\n",
    "To add a row, you must first create a new data frame containing all of the columns and their values (in key:value pairs) that you want to add to the new row (do so by editing the text in the double quotation marks in the first line, and adding new key:value pairs where necessary). \n",
    "\n",
    "This will then be combined with the current file (channels_tsv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add70770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new data frame for the new row\n",
    "new_channels_row = pd.DataFrame([{\"name\": \"F3\", \"type\": EEG, \"units\":\"V\"}])\n",
    "\n",
    "# Combining the new row with the existing channels_tsv data frame\n",
    "channels_tsv = pd.concat([channels_tsv, new_channels_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae636ba",
   "metadata": {},
   "source": [
    "Finally, after completing any necessary changes, we __must__ write them back to the file with the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82097d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the change to the file\n",
    "channels_tsv.to_csv(channels_path, sep= '\\t', index=False, na_rep='n/a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf93bd3f",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d72916",
   "metadata": {},
   "source": [
    "# Electrodes Description TSV\n",
    "This should have a format simlilar to *_electrodes.tsv in your 'eeg' subfolder. \n",
    "\n",
    "Once you have located the file, you should open it and look through the components it lists. Below is a list of information BIDS needs/suggests for this file. Take note of which elemets are missing/incorrect.\n",
    ">\n",
    "#### BIDS components:\n",
    ">\n",
    "Necessary:\n",
    ">\n",
    "    1. X\n",
    "    2. Y\n",
    "    3. Z\n",
    ">\n",
    "Recommended:\n",
    ">\n",
    "    4. Type\n",
    "    5. Material\n",
    "    6. Impedance\n",
    ">\n",
    "Optional:\n",
    ">\n",
    "    n/a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e455eadf",
   "metadata": {},
   "source": [
    "## Manually updating the electrodes.tsv file:\n",
    "To edit this file, we must first edit the double quotation marks (\"\") to match the full name of your `electrodes.tsv` file, which will be combined with 'eeg_root' to create the file path.  \n",
    "\n",
    "This will ensure that the variable `electrodes_tsv` refers to the file we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5d0849",
   "metadata": {},
   "outputs": [],
   "source": [
    "electrodes_path = eeg_root / \"sub-S001_space-CapTrak_electrodes.tsv\"\n",
    "# Assigning the electrodes.tsv file to a variable\n",
    "electrodes_tsv = pd.read_csv(electrodes_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25a8c5f",
   "metadata": {},
   "source": [
    "#### Adding/ Editing a column:\n",
    "\n",
    "Both of these functions can be managed using the same section of code!\n",
    "\n",
    "First, you should edit the 'Inputs' list to include the variables you wish to add to your new or pre-existing column. This should be done in electrode order, beginning with the entry for the first electrode in the file, and an entry must be submitted for each row.\n",
    "\n",
    "Then, you should change the text in double quotation marks (\"\") within `electrodes_tsv[\"__\"]`, to either title of the pre-existing column you wish to add to, or the title of the new column you wish to generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecdfa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing the desired inputs for the \"z\" column\n",
    "Inputs = [\"0.0\", \"0.049\", \"-0.039\", \"0.07\"]  \n",
    "\n",
    "# Setting the rows in the \"z\" column to the inputs listed above\n",
    "electrodes_tsv[\"z\"] = Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7777b1b7",
   "metadata": {},
   "source": [
    "#### Editing one row:\n",
    " \n",
    "To edit a single row, you must use the `.loc` function, which allows us to select a row via it's label. In this case, we will use 'name', by editing the electrode name (in the second set of double quotation marks) to match that of the row you'd like to edit. \n",
    "\n",
    "From there, you can edit the column name to match the one you'd like to edit (in the third set of double quotation marks) and then the item you'd like to assign to the location (in the fourth set of double quotation marks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f641e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Editing just one row in the electrodes.tsv file\n",
    "electrodes_tsv.loc[electrodes_tsv[\"name\"] == \"CP5\", \"y\"] = \"0.03\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9aa3bd",
   "metadata": {},
   "source": [
    "#### Removing a row:\n",
    "\n",
    "To remove a row, you must use the `.drop` function, to which you assign an index, which is the number assigned to the row you wish to remove. \n",
    "> Note: Indexes begin from 0, so the 'first' row will be #0, the 'second' row will be #1 and so on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b6abfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing a row from the electrodes.tsv file using the row's index\n",
    "electrodes_tsv = electrodes_tsv.drop(index=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f500f64e",
   "metadata": {},
   "source": [
    "#### Adding a row:\n",
    "\n",
    "To add a row, you must first create a new data frame containing all of the columns and their values (in key:value pairs) that you want to add to the new row (do so by editing the text in the double quotation marks in the first line, and adding new key:value pairs where necessary). \n",
    "\n",
    "This will then be combined with the current data frame (electrodes_tsv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c90e569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new data frame for the new row\n",
    "new_electrodes_row = pd.DataFrame([{\"name\": \"F3\", \"x\": -0.04 \"y\":\"-0.005\", \"z\": \"0.0\"}])\n",
    "\n",
    "# Combining the new row with the existing electrodes_tsv data frame\n",
    "electrodes_tsv = pd.concat([electrodes_tsv, new_electrodes_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a7a254",
   "metadata": {},
   "source": [
    "Finally, after completing any necessary changes, we __must__ write them back to the file with the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0011e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the change to the file\n",
    "electrodes_tsv.to_csv(electrodes_path, sep= '\\t', index=False, na_rep='n/a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0695bc77",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b34933",
   "metadata": {},
   "source": [
    "# Coordinate System JSON\n",
    "This should have a naming format simlilar to *_coordsystem.json in your 'eeg' subfolder. \n",
    "\n",
    "Once you have located the file, you should open it and look through its variables. Below is a list of information BIDS needs/suggests for this file. \n",
    ">Take note of any elements that are missing/incorrect; these can be updated using the next section of code.\n",
    "\n",
    "#### BIDS components:\n",
    ">\n",
    "Necessary:\n",
    ">\n",
    "    1. EEGCoordinateSystem\n",
    "    2. EEGCoordinateUnits\n",
    "    3. EEGCoordinateSystemDescription\n",
    "Recommended:\n",
    ">\n",
    "    4. FiducialsDescription\n",
    "    5. FiducialsCoordinates\n",
    "    6. FiducialsCoordinateSystem\n",
    "    7. FiducialsCoordinateUnits\n",
    "    8. FiducialsCoordinateSystemDescription\n",
    "    9. AnatomicalLandmarkCoordinates\n",
    "    10. AnatomicalLandmarkCoordinateSystem\n",
    "    11. AnatomicalLandmarkCoordinateUnits\n",
    "    12. AnatomicalLandmarkCoordinateSystemDescription\n",
    ">\n",
    "Optional:\n",
    ">\n",
    "    13. IntendedFor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4386fe0b",
   "metadata": {},
   "source": [
    "## Manually updating an element in the JSON file\n",
    "As with the sidecar file, the first line of code should be edited to include your coordinate file's name in the double quotation marks (\"\"). This will be combined with 'eeg_root' to set your file pathway. Additionally, you must change the `subject=` and `space=` sections of `bids_path1` to match your dataset's file name.\n",
    "\n",
    "For this file, the `space=` section is defined as CapTrak; if you were using a different coordinate system, its name should be inputted here instead.\n",
    "\n",
    "Once these are re-defined, you can update one or more aspect(s) of the sidecar using the `entries = {}` dictionary. This accepts `key:value` pairs, separated by colons (:), wherein single quotation marks ('') indicate a variable name, while double quotation marks (\"\") indicate it's data entry.\n",
    ">\n",
    "##### The code below will display an example of a few formats the key-value pairs can present in, such as:\n",
    ">\n",
    "__Written__\n",
    "    - A key-value pair where the value is a string (text).\n",
    ">\n",
    "__Nested dictionary (1 level)__\n",
    "    - A key-value pair where the value is a dictionary containing key-value pairs.\n",
    ">\n",
    "- Note: This file will accept key-value pairs in other formats, but those represented here are the only formats _necessary_.\n",
    "\n",
    "> An example output file can be found within the [BIDS documentation](https://bids-specification.readthedocs.io/en/stable/modality-specific-files/electroencephalography.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05d3a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating a specific item in the coordinate system JSON file\n",
    "json_file = Path(eeg_root / \"sub-S001_space-CapTrak_coordsystem.json\").absolute()\n",
    "\n",
    "bids_path1 = BIDSPath(subject='001', task=None,\n",
    "                     suffix='coordsystem', extension='.json', datatype='eeg',\n",
    "                     root=root, space='CapTrak')\n",
    "\n",
    "entries = { # Simple key-value pair for EEG Coordinate System (written)\n",
    "            'EEGCoordinateSystem':\"CapTrak\",\n",
    "            # Nested dictionary for Anatomical Landmark Coordinates, with list values (1-level)\n",
    "            'AnatomicalLandmarkCoordinates': {\n",
    "                'Nasion': [0.0, 0.0, 0.0],\n",
    "                'Left Preauricular': [-0.1, 0.0, 0.0],\n",
    "                'Right Preauricular': [0.1, 0.0, 0.0]\n",
    "            },\n",
    "            }       \n",
    "# Update the JSON file with your new entries\n",
    "update_sidecar_json(bids_path1, entries, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6428e4ea",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280c7d49",
   "metadata": {},
   "source": [
    "# Events TSV\n",
    "This file's name should have a format simlilar to *_events.tsv in your 'eeg' subfolder. \n",
    "\n",
    "This is the main dataset file for 'events', containing the table of variables and their values, which are defined in the json file.\n",
    "\n",
    "Once you have located this file, you should open it and look through it's variables. Below is a list of information BIDS needs/suggests for this file. \n",
    "> Take note of any elements that are missing/incorrect; these can be updated using the next section of code.\n",
    ">\n",
    "#### BIDS components:\n",
    ">\n",
    "Necessary:\n",
    ">\n",
    "    1. Onset\n",
    "    2. Duration\n",
    ">\n",
    "Recommended:\n",
    ">\n",
    "    n/a\n",
    ">\n",
    "Optional:\n",
    ">\n",
    "    3. TrialType\n",
    "    4. ResponseTime\n",
    "    5. HED\n",
    "    6. StimFile\n",
    "    7. Channel\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3f1d5e",
   "metadata": {},
   "source": [
    "## Manually updating the events.tsv file:\n",
    "To edit this file, we must first edit the double quotation marks (\"\") to match the full name of your `events.tsv` file, which will be combined with the 'eeg_root' variable to create the file path.  \n",
    "\n",
    "This will ensure that the variable `events_tsv` refers to the file we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151bb07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the events.tsv file to a variable\n",
    "events_path = eeg_root / \"sub-S001_task-task1_events.json\"\n",
    "events_tsv = pd.read_csv(events_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601ef772",
   "metadata": {},
   "source": [
    "#### Adding/ Editing a column:\n",
    "\n",
    "Both of these functions can be managed using the same section of code!\n",
    "\n",
    "First, you should edit the 'Inputs' list to include the variables you wish to add to your new or pre-existing column. This should be done in onset order, beginning with the entry for the first event in the file, and an entry must be submitted for each row.\n",
    "\n",
    "Then, you should change the text in double quotation marks (\"\") within `events_tsv[\"__\"]`, to either title of the pre-existing column you wish to add to, or the title of the new column you wish to generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab65e408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing the desired inputs for the \"duration\" column\n",
    "Inputs = [10.00, 0.001, 0.005, 0.5]  \n",
    "\n",
    "# Setting the rows in the \"duration\" column to the inputs listed above\n",
    "events_tsv[\"duration\"] = Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5af057",
   "metadata": {},
   "source": [
    "#### Editing one row:\n",
    " \n",
    "To edit a single row, you must use the `.loc` function, which allows us to select a row via it's label. In this case, we will use onset, by editing the onset number (in the second set of double quotation marks) to match that of the row you'd like to edit. \n",
    "\n",
    "From there, you can edit the column name to match the one you'd like to edit (in the third set of double quotation marks) and then the item you'd like to assign to the location (in the fourth set of double quotation marks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ea8ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Editing just one row in the events.tsv file\n",
    "events_tsv.loc[events_tsv[\"onset\"] == \"121.052\", \"duration\"] = \"0.001\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc0c857",
   "metadata": {},
   "source": [
    "#### Removing a row:\n",
    "\n",
    "To remove a row, you must use the `.drop` function, to which you assign an index, which is the number assigned to the row you wish to remove. \n",
    "> Note: Indexes begin from 0, so the 'first' row will be #0, the 'second' row will be #1 and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538f2b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing a row from the events.tsv file using the row's index\n",
    "events_tsv = events_tsv.drop(index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521afbce",
   "metadata": {},
   "source": [
    "#### Adding a row:\n",
    "\n",
    "To add a row, you must first create a new data frame containing all of the columns and their values (in key:value pairs) that you want to add to the new row (do so by editing the text in the double quotation marks in the first line, and adding new key:value pairs where necessary). \n",
    "\n",
    "This will then be combined with the current data frame (events_tsv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd76614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new data frame for the new row\n",
    "new_events_row = pd.DataFrame([{\"participant_id\": \"sub-002\", \"age\": 30, \"sex\":\"M\"}])\n",
    "\n",
    "# Combining the new row with the existing events_tsv data frame\n",
    "events_tsv = pd.concat([events_tsv, new_events_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0955ca8",
   "metadata": {},
   "source": [
    "Finally, after completing any necessary changes, we __must__ write them back to the file with the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bf44cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the change to the file\n",
    "events_tsv.to_csv(events_path, sep= '\\t', index=False, na_rep='n/a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12c7a2c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f91b9da",
   "metadata": {},
   "source": [
    "# Events JSON\n",
    "This file's name should have a format simlilar to *_events.json in your 'eeg' subfolder. \n",
    "\n",
    "This will serve as the explanatory counterpart to the events.tsv file. Any edits made to the contents of the tsv file should be mirrored here, with a description.\n",
    "\n",
    "Once you have located the file, you should open it and look through it. Below is a list of information BIDS needs/suggests for this file. \n",
    "> Take note of any elements that are missing/incorrect; these can be updated using the next section of code.\n",
    ">\n",
    "#### BIDS components:\n",
    ">\n",
    "Necessary:\n",
    ">\n",
    "    1. Onset\n",
    "    2. Duration\n",
    ">\n",
    "Recommended:\n",
    ">\n",
    "    n/a\n",
    ">\n",
    "Optional:\n",
    ">\n",
    "    3. TrialType\n",
    "    4. ResponseTime\n",
    "    5. HED\n",
    "    6. StimFile\n",
    "    7. Channel\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cf72e7",
   "metadata": {},
   "source": [
    "## Manually editing an element in the JSON file\n",
    "Similarly to the procedure for the other JSON files, you should edit the first line of code to include your events file's name in the double quotation marks (\"\"). This will be combined with 'eeg_root' to set your file pathway. Additionally, you must change the `subject=` and `task=` sections of `bids_path1` to match your dataset's file name.\n",
    "\n",
    "Once these are re-defined, you can update one or more aspect(s) of the sidecar using the `entries = {}` dictionary. This accepts `key:value` pairs, separated by colons (:), wherein single quotation marks ('') indicate a variable name, while double quotation marks (\"\") indicate it's data entry.\n",
    ">\n",
    "##### The code below will display an example of a few formats the key-value pairs can present in, such as:\n",
    "__Nested dictionary (1 level)__\n",
    "    - A key-value pair where the value is a dictionary containing key-value pairs.\n",
    ">\n",
    "__Nested dictionary (2+ levels)__\n",
    "    - A key-value pair where the value is a dictionary that contains one or more dictionaries.\n",
    ">\n",
    "\n",
    "- Note: This file will accept key-value pairs in other formats, but those represented here are the most common.\n",
    "\n",
    " > An example output file can be found within the [BIDS documentation](https://bids-specification.readthedocs.io/en/stable/modality-specific-files/electroencephalography.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6196304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating a specific item in the events JSON file\n",
    "json_file = Path(eeg_root / \"sub-S001_task-task1_events.json\").absolute()\n",
    "\n",
    "bids_path1 = BIDSPath(subject='001', task='rest',\n",
    "                     suffix='events', extension='.json', datatype='eeg',\n",
    "                     root=root)\n",
    "\n",
    "entries = {# Nested dictionary for event duration containing description and units (1-level)\n",
    "        'Duration':{'Description': \"Duration of the event in seconds.\", 'Units': \"Seconds\"},\n",
    "         # Nested dictionary for trial type containing name, description, and levels (2-levels)\n",
    "        'TrialType':{'Name':\"Event Category\", \n",
    "                     'Description': \"Indicator of the type of action that is expected.\", \n",
    "                     'Levels': {\n",
    "                        'Start': \"A red square appears on the screen to indicate the start of a trial.\",\n",
    "                        'Stop': \"A green square appears on the screen to indicate the end of a trial\"}\n",
    "                     },\n",
    "         # Nested dictionary for stim file containing description, file type, and file path (1-level)\n",
    "        'Stim File': {'Description': \"File containing the stimulus presentation information for the event.\", 'FileType': \"CSV\", 'FilePath': \"sub-001_task-rest_stim.csv\"},\n",
    "        }     \n",
    "# Update the JSON file with your new entries  \n",
    "update_sidecar_json(bids_path1, entries, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e00c67e",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dfeaab",
   "metadata": {},
   "source": [
    "# Participants TSV\n",
    "The participants.tsv file includes a table containing participant information relavant to the dataset. It is accompanied by the participants.json file, which provides more in-depth explanations for this information.\n",
    ">\n",
    "MNE-BIDS will automatically input the majority of this information, but you may wish to edit the file in order to add more columns to include further participant information.\n",
    "\n",
    "#### BIDS Components:\n",
    ">\n",
    "Necessary:\n",
    ">\n",
    "    1. Participant ID \n",
    ">\n",
    "Recommended:\n",
    ">\n",
    "    2. Species\n",
    "    3. Age\n",
    "    4. Sex\n",
    "    5. Handedness\n",
    "    6. Strain\n",
    "    7. Strain RRID\n",
    ">\n",
    "Optional:\n",
    ">\n",
    "    - Additional participant information may be included to further bolster your metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebd5922",
   "metadata": {},
   "source": [
    "## Manually updating the participants.tsv file:\n",
    "To edit this file, we must first edit the double quotation marks (\"\") to match the full name of your `participants.tsv` file, which will be combined with the 'eeg_root' variable to create the file path.  \n",
    "\n",
    "This will ensure that the variable `participants_tsv` refers to the file we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b34d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "participants_path = root / \"participants.tsv\"\n",
    "# Assigning the participants.tsv file to a variable\n",
    "participants_tsv = pd.read_csv(participants_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a5ebf9",
   "metadata": {},
   "source": [
    "#### Adding/ Editing a column:\n",
    "\n",
    "Both of these functions can be managed using the same section of code!\n",
    "\n",
    "First, you should edit the 'Inputs' list to include the variables you wish to add to your new or pre-existing column. This should be done in participant order, beginning with the entry for the first participant in the file, and an entry must be submitted for each row.\n",
    "\n",
    "Then, you should change the text in double quotation marks (\"\") within `participants_tsv[\"__\"]`, to either title of the pre-existing column you wish to add to, or the title of the new column you wish to generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bbd995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing the desired inputs for the \"Education\" column\n",
    "Inputs = [\"High School\", \"A-level\", \"Bachelors\", \"PhD\"]  \n",
    "\n",
    "# Setting the rows in the \"Education\" column to the inputs listed above\n",
    "participants_tsv[\"Education\"] = Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9e7a3f",
   "metadata": {},
   "source": [
    "#### Editing one row:\n",
    " \n",
    "To edit a single row, you must use the `.loc` function, which allows us to select a row via it's label. In this case, we will use participant ID, by editing the participant ID number (in the second set of double quotation marks) to match that of the row you'd like to edit. \n",
    "\n",
    "From there, you can edit the column name to match the one you'd like to edit (in the third set of double quotation marks) and then the item you'd like to assign to the location (in the fourth set of double quotation marks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3821fba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Editing just one row in the participants.tsv file\n",
    "participants_tsv.loc[participants_tsv[\"participant_id\"] == \"sub-001\", \"Education\"] = \"none\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7bdcfb",
   "metadata": {},
   "source": [
    "#### Removing a row:\n",
    "\n",
    "To remove a row, you must use the `.drop` function, to which you assign an index, which is the number assigned to the row you wish to remove. \n",
    "> Note: Indexes begin from 0, so the 'first' row will be #0, the 'second' row will be #1 and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38ab43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing a row from the participants.tsv file using the row's index\n",
    "participants_tsv = participants_tsv.drop(index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d35d1ee",
   "metadata": {},
   "source": [
    "#### Adding a row:\n",
    "\n",
    "To add a row, you must first create a new data frame containing all of the columns and their values (in key:value pairs) that you want to add to the new row (do so by editing the text in the double quotation marks in the first line, and adding new key:value pairs where necessary). \n",
    "\n",
    "This will then be combined with the current data frame (participants_tsv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4715ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new data frame for the new row\n",
    "new_participants_row = pd.DataFrame([{\"participant_id\": \"sub-002\", \"age\": 30, \"sex\":\"M\"}])\n",
    "\n",
    "# Combining the new row with the existing participants_tsv data frame\n",
    "participants_tsv = pd.concat([participants_tsv, new_participants_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad1f855",
   "metadata": {},
   "source": [
    "Finally, after completing any necessary changes, we __must__ write them back to the file with the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ed5fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the change to the file\n",
    "participants_tsv.to_csv(participants_path, sep= '\\t', index=False, na_rep='n/a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558ed33e",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61da025",
   "metadata": {},
   "source": [
    "# Participants JSON\n",
    "The participants.json file exists as a counterpart to the participants.tsv file and is used to describe the TSV column names and the properties of their values, making interpretation easier, especially in the case of dataset-specific columns. \n",
    ">\n",
    "MNE-BIDS will automatically input the majority of this information, but you may wish to edit these descriptions to be more accurate, and should add additional descriptions for each new entry added to the participants.tsv file (e.g. education level).\n",
    "\n",
    "#### BIDS Components:\n",
    ">\n",
    "Necessary:\n",
    ">\n",
    "    1. Participant ID \n",
    ">\n",
    "Recommended:\n",
    ">\n",
    "    2. Species\n",
    "    3. Age\n",
    "    4. Sex\n",
    "    5. Handedness\n",
    "    6. Strain\n",
    "    7. Strain RRID\n",
    ">\n",
    "Optional:\n",
    ">\n",
    "    - Additional participant information may be included to further bolster your metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dc4002",
   "metadata": {},
   "source": [
    "## Manually updating an element in the participants.json file: \n",
    ">\n",
    "To begin, you must edit the first line of code to include your 'participants' file's name in the double quotation marks (\"\"). This will be combined with 'root' to set your file pathway.\n",
    "\n",
    "Once these are re-defined, you can update one or more aspect(s) of the sidecar using the `entries = {}` dictionary. This accepts `key:value` pairs, separated by colons (:), wherein single quotation marks ('') indicate a variable name, while double quotation marks (\"\") indicate it's data entry.\n",
    ">\n",
    "##### The code below will display an example of a few formats the key-value pairs can present in, such as:\n",
    ">\n",
    "__Nested dictionary (1 level)__\n",
    "    - A key-value pair where the value is a dictionary containing key-value pairs.\n",
    ">\n",
    "__Nested dictionary (2+ levels)__\n",
    "    - A key-value pair where the value is a dictionary that contains one or more dictionaries.\n",
    "\n",
    "- Note: This file will accept key-value pairs in other formats, but those represented here are the most common.\n",
    "\n",
    "> An example output file can be found within the [BIDS documentation](https://bids-specification.readthedocs.io/en/stable/modality-agnostic-files.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165f78cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for adding information to the participants.json file\n",
    "json_file = Path(root / \"participants.json\").absolute()\n",
    "\n",
    "bids_path1 = BIDSPath(subject=None, task=None,\n",
    "                     suffix='participants', extension='.json', datatype=None,\n",
    "                     root=root)\n",
    "\n",
    "entries = { # Nested dictionary for age containing description and units (1-level)\n",
    "            'Age': {'Description': \"Age of the participant at time of testing\", 'Units': \"Years\"}, \n",
    "            # Nested dictionary for handedness containing description and levels (2-levels)\n",
    "            'Handedness': {'Description': \"Handedness of the participant\",\n",
    "                        'Levels': {\n",
    "                            \"R\": \"Right-handed\",\n",
    "                            \"L\": \"Left-handed\",\n",
    "                            \"A\": \"Ambidextrous\"\n",
    "                        }\n",
    "                },\n",
    "        }       \n",
    "update_sidecar_json(bids_path1, entries, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19460a4d",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b010fcf",
   "metadata": {},
   "source": [
    "# Phenotype JSON\n",
    "> Optional\n",
    "> Datasets with multiple sets of participant level measurements (such as responses from multiple questionnaires) may benefit from being split into files separate from the participants files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2179f5b",
   "metadata": {},
   "source": [
    "The only requirements for these files are that their first column is participant_id, that their rows correspond directly with the subjects in the BIDS dataset, and they have a descriptive name. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d125459d",
   "metadata": {},
   "source": [
    "First, we must create the folder we want to write the file to. \n",
    "\n",
    "In the file path section, we will be adding \"phenotype\" to the end of our 'root' file pathway to create a new folder named 'phenotype' there. You must then define the file name you wish to create by editing `\"descriptive_file_name.tsv\"` to include a file name that accurately represents the contents of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faf24b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotype_1_folder = Path(root / \"phenotype\")\n",
    "phenotype_1_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "phenotype_tsv_path = phenotype_1_folder / \"descriptive_file_name.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ceda44",
   "metadata": {},
   "source": [
    "Now, you can add your data to the key:value pairs in the dictionary below to set the contents of the tsv file. \n",
    "\n",
    "The 'keys' will become the column headers, while the 'values' will be the data assigned to each row for that header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3cf7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotype_1 = {\n",
    "        'participant_id': [\"Sub-001\", \"Sub-002\"], \n",
    "        'Subjective_SES': 10\n",
    "}\n",
    "descriptive_file_name_phenotype = pd.DataFrame(phenotype_1)\n",
    "\n",
    "descriptive_file_name_phenotype.to_csv(phenotype_tsv_path, sep=\"\\t\", index=False, na_rep=\"n/a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b098e1",
   "metadata": {},
   "source": [
    "#### It is recommended that this file is accompanied by a descriptive json file, explaining each of its columns.\n",
    "First, let's create the file path for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e35b00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotype_json_path = phenotype_1_folder / \"descriptive_file_name.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917db244",
   "metadata": {},
   "source": [
    "Next, edit the 'entries' dictionary to include the description information for every variable entered into the tsv file. This will accept key:value pair formats, including nested dictionaries.\n",
    "\n",
    "Then, we will write this to the json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f1d984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "entries = { \n",
    "        'participant_id': {\"Description\": \"The participant's unique idintifier code\"}, \n",
    "        'Subjective_SES': {\"Description\": \"The self-percieved socioeconomic status of the participant\", \"Scale\": \"The Mcarthur Scale of Subjective social status\"}\n",
    "        }       \n",
    "with open(phenotype_json_path, \"w\") as outfile:\n",
    "    json.dump(entries, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cfd456",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ee5b47",
   "metadata": {},
   "source": [
    "# How to cite MNE-BIDS\n",
    "\n",
    "#### As we used their tools to generate our BIDS formatted dataset, we must cite MNE-BIDS somewhere within it!\n",
    "The following code will automatically do this for you:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980bca8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "readme = op.join(bids_root, \"README\")\n",
    "with open(readme, encoding=\"utf-8-sig\") as fid:\n",
    "    text = fid.read()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de753fcd",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede764c4",
   "metadata": {},
   "source": [
    "# Our Citations\n",
    "MNE-BIDS\n",
    "> Appelhoff, S., Sanderson, M., Brooks, T., Vliet, M., Quentin, R., Holdgraf, C., Chaumon, M., Mikulan, E., Tavabi, K., Hchenberger, R., Welke, D., Brunner, C., Rockhill, A., Larson, E., Gramfort, A., & Jas, M. (2019). MNE-BIDS: Organizing electrophysiological data into the BIDS format and facilitating their analysis. Journal of Open Source Software, 4:1896. DOI: 10.21105/joss.01896\n",
    ">\n",
    ">  Pernet, C.R., Appelhoff, S., Gorgolewski, K.J. et al. EEG-BIDS, an extension to the brain imaging data structure for electroencephalography. Sci Data 6, 103 (2019). https://doi.org/10.1038/s41597-019-0104-8\n",
    ">\n",
    "MNE-Python\n",
    "> Alexandre Gramfort, Martin Luessi, Eric Larson, Denis A. Engemann, Daniel Strohmeier, Christian Brodbeck, Roman Goj, Mainak Jas, Teon Brooks, Lauri Parkkonen, and Matti S. Hmlinen. MEG and EEG data analysis with MNE-Python. Frontiers in Neuroscience, 7(267):113, 2013. doi:10.3389/fnins.2013.00267.\n",
    ">\n",
    "BIDS\n",
    "> Gorgolewski, K.J., Auer, T., Calhoun, V.D., Craddock, R.C., Das, S., Duff, E.P., Flandin, G., Ghosh, S.S., Glatard, T., Halchenko, Y.O., Handwerker, D.A., Hanke, M., Keator, D., Li, X., Michael, Z., Maumet, C., Nichols, B.N., Nichols, T.E., Pellman, J., Poline, J.-B., Rokem, A., Schaefer, G., Sochat, V., Triplett, W., Turner, J.A., Varoquaux, G., Poldrack, R.A. (2016). The brain imaging data structure, a format for organizing and describing outputs of neuroimaging experiments. Scientific Data, 3 (160044). doi:10.1038/sdata.2016.44\n",
    ">\n",
    ">  Pernet, C. R., Appelhoff, S., Gorgolewski, K.J., Flandin, G., Phillips, C., Delorme, A., Oostenveld, R. (2019). EEG-BIDS, an extension to the brain imaging data structure for electroencephalography. Scientific data, 6 (103). doi:10.1038/s41597-019-0104-8\n",
    ">\n",
    "EEG Motor Movement/Imagery Dataset\n",
    "> Schalk, G., McFarland, D.J., Hinterberger, T., Birbaumer, N., Wolpaw, J.R. BCI2000: A General-Purpose Brain-Computer Interface (BCI) System. IEEE Transactions on Biomedical Engineering 51(6):1034-1043, 2004.\n",
    ">\n",
    "PhysioNet\n",
    "> Goldberger, A., Amaral, L., Glass, L., Hausdorff, J., Ivanov, P. C., Mark, R., ... & Stanley, H. E. (2000). PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research resource for complex physiologic signals. Circulation [Online]. 101 (23), pp. e215e220. RRID:SCR_007345.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea777d3",
   "metadata": {},
   "source": [
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
